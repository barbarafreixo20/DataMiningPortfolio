{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Esta implementação define uma classe Dataset para lidar com conjuntos de dados tabulares. A classe possui os seguintes atributos:\n",
        "\n",
        "* X: Uma matriz que armazena as variáveis independentes (também chamadas de características de entrada).\n",
        "* y: Um vetor que armazena a variável dependente (também chamada de variável de saída ou alvo).\n",
        "* feature_names: Uma lista com os nomes de cada característica de entrada.\n",
        "label_name: O nome da característica de saída.\n",
        "* discrete_values: Um dicionário para armazenar os possíveis valores para cada característica discreta.\n",
        "\n",
        "A classe possui vários métodos para ler e escrever arquivos CSV/TSV, calcular estatísticas e lidar com missing values:\n",
        "\n",
        "* read_csv: Lê um arquivo CSV/TSV e preenche os atributos X, y, feature_names e label_name.\n",
        "\n",
        "* write_csv: Escreve o conjunto de dados num arquivo CSV/TSV, incluindo os nomes das características e do rótulo (se disponível).\n",
        "\n",
        "* describe: Calcula estatísticas para cada característica em X, como médias, desvios padrão, valores mínimos e máximos.\n",
        "\n",
        "* find_missing_values: Identifica missing values no conjunto de dados e retorna uma matriz booleana com a mesma forma que X, onde True indica um missing value.\n",
        "\n",
        "* count_missing_values: Conta o número de missing values em cada coluna das características.\n",
        "\n",
        "* replace_missing_values: Substitui os missing values no conjunto de dados por um valor constante especificado ou pela média/mediana da coluna da característica correspondente.\n",
        "\n",
        "A classe também possui métodos \"getter\" e \"setter\" para aceder e modificar os atributos."
      ],
      "metadata": {
        "id": "lDD_rqa8Lvdt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "\n",
        "class Dataset:\n",
        "    def __init__(self, X=None, y=None, feature_names=None, label_name=None):\n",
        "\n",
        "        \"\"\"\n",
        "        Inicializa um objeto da classe Dataset.\n",
        "\n",
        "        Parâmetros:\n",
        "        - X (numpy array, opcional): Matriz com as variáveis independentes.\n",
        "        - y (numpy array, opcional): Vetor com a variável dependente.\n",
        "        - feature_names (list, opcional): Lista com os nomes das características de entrada.\n",
        "        - label_name (str, opcional): Nome da característica de saída.\n",
        "        \"\"\"\n",
        "\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.feature_names = feature_names\n",
        "        self.label_name = label_name\n",
        "        self.discrete_values = {}\n",
        "\n",
        "    def get_X(self):\n",
        "        \"\"\"Retorna a matriz X com as variáveis independentes.\"\"\"\n",
        "        return self.X\n",
        "\n",
        "    def get_y(self):\n",
        "        \"\"\"Retorna o vetor y com a variável dependente.\"\"\"\n",
        "        return self.y\n",
        "\n",
        "    def get_feature_names(self):\n",
        "        \"\"\"Retorna a lista com os nomes das características de entrada.\"\"\"\n",
        "        return self.feature_names\n",
        "\n",
        "    def get_label_name(self):\n",
        "        \"\"\"Retorna o nome da característica de saída.\"\"\"\n",
        "        return self.label_name\n",
        "\n",
        "    def set_X(self, X):\n",
        "        \"\"\"\n",
        "        Define a matriz X com as variáveis independentes.\n",
        "\n",
        "        Parâmetro:\n",
        "        - X (numpy array): Matriz com as variáveis independentes.\n",
        "        \"\"\"\n",
        "        self.X = X\n",
        "\n",
        "    def set_y(self, y):\n",
        "        \"\"\"\n",
        "        Define o vetor y com a variável dependente.\n",
        "\n",
        "        Parâmetro:\n",
        "        - y (numpy array): Vetor com a variável dependente.\n",
        "        \"\"\"\n",
        "        self.y = y\n",
        "\n",
        "    def set_feature_names(self, feature_names):\n",
        "        \"\"\"\n",
        "        Define a lista com os nomes das características de entrada.\n",
        "\n",
        "        Parâmetro:\n",
        "        - feature_names (list): Lista com os nomes das características de entrada.\n",
        "        \"\"\"\n",
        "        self.feature_names = feature_names\n",
        "\n",
        "    def set_label_name(self, label_name):\n",
        "        \"\"\"\n",
        "        Define o nome da característica de saída.\n",
        "\n",
        "        Parâmetro:\n",
        "        - label_name (str): Nome da característica de saída.\n",
        "        \"\"\"\n",
        "        self.label_name = label_name\n",
        "\n",
        "    def read_csv(self, filepath, delimiter=',', has_header=True):\n",
        "        \"\"\"\n",
        "        Lê um arquivo CSV/TSV e preenche os atributos X, y, feature_names e label_name.\n",
        "\n",
        "        Parâmetros:\n",
        "        - filepath (str): Caminho do arquivo CSV/TSV.\n",
        "        - delimiter (str, opcional): Delimitador usado no arquivo CSV/TSV. Padrão é ','.\n",
        "        - has_header (bool, opcional): Indica se o arquivo CSV/TSV possui cabeçalho. Padrão é True.\n",
        "        \"\"\"\n",
        "        with open(filepath, 'r') as file:\n",
        "            reader = csv.reader(file, delimiter=delimiter)\n",
        "            if has_header:\n",
        "                header = next(reader)\n",
        "                self.feature_names = header[:-1]\n",
        "                self.label_name = header[-1]\n",
        "            data = list(reader)\n",
        "        data = np.array(data, dtype=object)\n",
        "        self.X = data[:, :-1].astype(np.float64)\n",
        "        self.y = np.round(data[:, -1].astype(np.float64)).astype(np.int64)\n",
        "\n",
        "    def write_csv(self, filepath, delimiter=','):\n",
        "        \"\"\"\n",
        "        Escreve o conjunto de dados num arquivo CSV/TSV, incluindo os nomes das características e do rótulo (se disponível).\n",
        "\n",
        "        Parâmetros:\n",
        "        - filepath (str): Caminho do arquivo CSV/TSV.\n",
        "        - delimiter (str, opcional): Delimitador usado no arquivo CSV/TSV. Padrão é ','.\"\"\"\n",
        "        data = np.column_stack((self.X, self.y))\n",
        "        with open(filepath, 'w') as file:\n",
        "            writer = csv.writer(file, delimiter=delimiter)\n",
        "            if self.feature_names is not None and self.label_name is not None:\n",
        "                writer.writerow(self.feature_names + [self.label_name])\n",
        "            writer.writerows(data)\n",
        "\n",
        "    def describe(self):\n",
        "        \"\"\"\n",
        "        Calcula e retorna as estatísticas do conjunto de dados (médias, desvios padrão, valores mínimos e máximos).\n",
        "\n",
        "        Retorna:\n",
        "        - means (numpy array): Médias das variáveis independentes.\n",
        "        - stds (numpy array): Desvios padrão das variáveis independentes.\n",
        "        - min_values (numpy array): Valores mínimos das variáveis independentes.\n",
        "        - max_values (numpy array): Valores máximos das variáveis independentes.\n",
        "        \"\"\"\n",
        "        means = np.mean(self.X.astype(np.float64), axis=0)\n",
        "        stds = np.std(self.X.astype(np.float64), axis=0)\n",
        "        min_values = np.min(self.X.astype(np.float64), axis=0)\n",
        "        max_values = np.max(self.X.astype(np.float64), axis=0)\n",
        "\n",
        "        return means, stds, min_values, max_values\n",
        "\n",
        "    def find_missing_values(self):\n",
        "        \"\"\"\n",
        "        Encontra missing values no conjunto de dados.\n",
        "\n",
        "        Retorna:\n",
        "        - missing_values (numpy array): Matriz booleana indicando a presença de missing values.\n",
        "        \"\"\"\n",
        "        return np.isnan(self.X.astype(np.float64))\n",
        "\n",
        "    def count_missing_values(self):\n",
        "        \"\"\"\n",
        "        Conta a quantidade de missing values no conjunto de dados.\n",
        "\n",
        "        Retorna:\n",
        "        - missing_count (numpy array): Vetor com a quantidade de missing values por variável independente.\n",
        "        \"\"\"\n",
        "        return np.sum(np.isnan(self.X.astype(np.float64)), axis=0)\n",
        "\n",
        "    def replace_missing_values(self, constant='mean'):\n",
        "        \"\"\"\n",
        "        Substitui os missing values no conjunto de dados usando uma constante fornecida, a média ou a mediana.\n",
        "\n",
        "        Parâmetro:\n",
        "        - constant (str ou numérico, opcional): Valor para substituir os missing values. Pode ser 'mean', 'median' ou um valor numérico. Padrão é 'mean'.\n",
        "        \"\"\"\n",
        "        missing = self.find_missing_values()\n",
        "        for i in range(self.X.shape[1]):\n",
        "            if constant == 'mean':\n",
        "                replacement = np.nanmean(self.X[:, i].astype(np.float64))\n",
        "            elif constant == 'median':\n",
        "                replacement = np.nanmedian(self.X[:, i].astype(np.float64))\n",
        "            else:\n",
        "                replacement = constant\n",
        "            self.X[:, i][missing[:, i]] = replacement"
      ],
      "metadata": {
        "id": "Mgn0C2NY8wOy"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testes e exemplos para o algoritmo implementado"
      ],
      "metadata": {
        "id": "Wdh49IYHQT9h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exemplo de uso do código"
      ],
      "metadata": {
        "id": "hboxzimgQkMY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta implementação demonstra como manipular e analisar um conjunto de dados utilizando a classe Dataset, além de mostrar como salvar e carregar os dados em formato CSV."
      ],
      "metadata": {
        "id": "o4PM35nnROXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "\n",
        "# Carrega o conjunto de dados iris\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "# Extrai os nomes das características e o nome do rótulo\n",
        "feature_names = iris.feature_names\n",
        "label_name = \"species\"\n",
        "\n",
        "# Cria uma instância da classe Dataset com os dados do iris\n",
        "dataset = Dataset(X=iris.data, y=iris.target, feature_names=feature_names, label_name=label_name)\n",
        "\n",
        "# Imprime algumas estatísticas\n",
        "means, stds, min_values, max_values = dataset.describe()\n",
        "print(\"Médias:\", means)\n",
        "print(\"Desvios padrão:\", stds)\n",
        "print(\"Valores mínimos:\", min_values)\n",
        "print(\"Valores máximos:\", max_values)\n",
        "\n",
        "# Encontra e conta os missing values\n",
        "missing_values = dataset.find_missing_values()\n",
        "print(\"Valores ausentes:\", missing_values)\n",
        "missing_count = dataset.count_missing_values()\n",
        "print(\"Contagem de valores ausentes:\", missing_count)\n",
        "\n",
        "# Escreve o conjunto de dados num arquivo CSV\n",
        "dataset.write_csv(\"iris.csv\")\n",
        "\n",
        "# Lê o conjunto de dados do arquivo CSV\n",
        "dataset_from_csv = Dataset()\n",
        "dataset_from_csv.read_csv(\"iris.csv\", delimiter=',', has_header=True)\n",
        "\n",
        "# Imprime algumas estatísticas do conjunto de dados lido do arquivo CSV\n",
        "means, stds, min_values, max_values = dataset_from_csv.describe()\n",
        "print(\"Médias (do CSV):\", means)\n",
        "print(\"Desvios padrão (do CSV):\", stds)\n",
        "print(\"Valores mínimos (do CSV):\", min_values)\n",
        "print(\"Valores máximos (do CSV):\", max_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFoAMIxY-wkw",
        "outputId": "c92ef493-3c78-49de-9c67-9e4e18bea76c"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Médias: [5.84333333 3.05733333 3.758      1.19933333]\n",
            "Desvios padrão: [0.82530129 0.43441097 1.75940407 0.75969263]\n",
            "Valores mínimos: [4.3 2.  1.  0.1]\n",
            "Valores máximos: [7.9 4.4 6.9 2.5]\n",
            "Valores ausentes: [[False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]]\n",
            "Contagem de valores ausentes: [0 0 0 0]\n",
            "Médias (do CSV): [5.84333333 3.05733333 3.758      1.19933333]\n",
            "Desvios padrão (do CSV): [0.82530129 0.43441097 1.75940407 0.75969263]\n",
            "Valores mínimos (do CSV): [4.3 2.  1.  0.1]\n",
            "Valores máximos (do CSV): [7.9 4.4 6.9 2.5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testes \"Unittest\""
      ],
      "metadata": {
        "id": "lYVkJdAsQ_YY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Foi realizado um teste utilizando o unittest para testar a implementação do Dataset. Temos então o seguinte teste:"
      ],
      "metadata": {
        "id": "tuiCGc2BRAc3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estes testes cobrem funções como getters e setters, leitura e escrita de arquivos CSV, descrição e manipulação de missing values."
      ],
      "metadata": {
        "id": "ie6Gh1gSTbsB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import unittest\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "import os\n",
        "import tempfile\n",
        "\n",
        "# Classe que contém os testes unitários para a classe Dataset\n",
        "class TestDataset(unittest.TestCase):\n",
        "\n",
        "    # Método executado antes de cada teste\n",
        "    def setUp(self):\n",
        "        iris = datasets.load_iris()\n",
        "        self.dataset = Dataset(X=iris.data, y=iris.target, feature_names=iris.feature_names, label_name=\"species\")\n",
        "\n",
        "    # Testa os métodos getter e setter da classe Dataset\n",
        "    def test_getters_and_setters(self):\n",
        "        X = self.dataset.get_X()\n",
        "        y = self.dataset.get_y()\n",
        "        feature_names = self.dataset.get_feature_names()\n",
        "        label_name = self.dataset.get_label_name()\n",
        "\n",
        "        self.assertIsNotNone(X)\n",
        "        self.assertIsNotNone(y)\n",
        "        self.assertIsNotNone(feature_names)\n",
        "        self.assertIsNotNone(label_name)\n",
        "\n",
        "        self.dataset.set_X(np.array([[1, 2], [3, 4]]))\n",
        "        self.dataset.set_y(np.array([1, 0]))\n",
        "        self.dataset.set_feature_names(['a', 'b'])\n",
        "        self.dataset.set_label_name('c')\n",
        "\n",
        "        self.assertTrue(np.array_equal(self.dataset.get_X(), np.array([[1, 2], [3, 4]])))\n",
        "        self.assertTrue(np.array_equal(self.dataset.get_y(), np.array([1, 0])))\n",
        "        self.assertEqual(self.dataset.get_feature_names(), ['a', 'b'])\n",
        "        self.assertEqual(self.dataset.get_label_name(), 'c')\n",
        "\n",
        "    # Testa a leitura e escrita de CSVs\n",
        "    def test_read_write_csv(self):\n",
        "        self.dataset.write_csv(\"test_iris.csv\")\n",
        "        dataset_from_csv = Dataset()\n",
        "        dataset_from_csv.read_csv(\"test_iris.csv\", delimiter=',', has_header=True)\n",
        "\n",
        "        self.assertTrue(np.array_equal(self.dataset.get_X(), dataset_from_csv.get_X()))\n",
        "        self.assertTrue(np.array_equal(self.dataset.get_y(), dataset_from_csv.get_y()))\n",
        "        self.assertEqual(self.dataset.get_feature_names(), dataset_from_csv.get_feature_names())\n",
        "        self.assertEqual(self.dataset.get_label_name(), dataset_from_csv.get_label_name())\n",
        "\n",
        "    # Testa a escrita de CSVs usando um arquivo temporário\n",
        "    def test_write_csv(self):\n",
        "        # Create a temporary file\n",
        "        with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n",
        "            temp_filepath = temp_file.name\n",
        "\n",
        "        # Write the dataset to the temporary file\n",
        "        self.dataset.write_csv(temp_filepath)\n",
        "\n",
        "        # Read the dataset from the temporary file\n",
        "        dataset_from_csv = Dataset()\n",
        "        dataset_from_csv.read_csv(temp_filepath, delimiter=',', has_header=True)\n",
        "\n",
        "        # Compare the read dataset with the original dataset\n",
        "        self.assertTrue(np.array_equal(self.dataset.get_X(), dataset_from_csv.get_X()))\n",
        "        self.assertTrue(np.array_equal(self.dataset.get_y(), dataset_from_csv.get_y()))\n",
        "        self.assertEqual(self.dataset.get_feature_names(), dataset_from_csv.get_feature_names())\n",
        "        self.assertEqual(self.dataset.get_label_name(), dataset_from_csv.get_label_name())\n",
        "\n",
        "        # Remove the temporary file\n",
        "        os.remove(temp_filepath)\n",
        "\n",
        "    # Testa a função \"describe\" da classe Dataset\n",
        "    def test_describe(self):\n",
        "        means, stds, min_values, max_values = self.dataset.describe()\n",
        "\n",
        "        self.assertIsNotNone(means)\n",
        "        self.assertIsNotNone(stds)\n",
        "        self.assertIsNotNone(min_values)\n",
        "        self.assertIsNotNone(max_values)\n",
        "\n",
        "    # Testa as funções relacionadas aos missing values\n",
        "    def test_missing_values(self):\n",
        "        missing_values = self.dataset.find_missing_values()\n",
        "        self.assertIsNotNone(missing_values)\n",
        "        self.assertEqual(missing_values.shape, self.dataset.get_X().shape)\n",
        "\n",
        "        missing_count = self.dataset.count_missing_values()\n",
        "        self.assertIsNotNone(missing_count)\n",
        "        self.assertEqual(missing_count.shape, (self.dataset.get_X().shape[1],))\n",
        "\n",
        "    # Testa a função \"replace_missing_values\" da classe Dataset\n",
        "    def test_replace_missing_values(self):\n",
        "        self.dataset.replace_missing_values(constant='mean')\n",
        "        missing_values = self.dataset.find_missing_values()\n",
        "        self.assertFalse(np.any(missing_values))\n",
        "\n",
        "    # Testa a função \"find_missing_values\" da classe Dataset\n",
        "    def test_find_missing_values(self):\n",
        "        # Create a dataset with some missing values\n",
        "        X = np.array([[1, np.nan, 3], [4, 5, np.nan], [7, 8, 9]])\n",
        "        y = np.array([0, 1, 2])\n",
        "        feature_names = ['a', 'b', 'c']\n",
        "        label_name = 'd'\n",
        "        dataset_with_missing_values = Dataset(X=X, y=y, feature_names=feature_names, label_name=label_name)\n",
        "\n",
        "        # Find missing values\n",
        "        missing_values = dataset_with_missing_values.find_missing_values()\n",
        "\n",
        "        # Check if the missing values are correctly identified\n",
        "        expected_missing_values = np.array([[False, True, False], [False, False, True], [False, False, False]])\n",
        "        self.assertTrue(np.array_equal(missing_values, expected_missing_values))\n",
        "\n",
        "    # Testa a função \"count_missing_values\" da classe Dataset\n",
        "    def test_count_missing_values(self):\n",
        "        # Create a dataset with some missing values\n",
        "        X = np.array([[1, np.nan, 3], [4, 5, np.nan], [7, 8, 9]])\n",
        "        y = np.array([0, 1, 2])\n",
        "        feature_names = ['a', 'b', 'c']\n",
        "        label_name = 'd'\n",
        "        dataset_with_missing_values = Dataset(X=X, y=y, feature_names=feature_names, label_name=label_name)\n",
        "\n",
        "        # Count missing values\n",
        "        missing_count = dataset_with_missing_values.count_missing_values()\n",
        "\n",
        "        # Check if the count of missing values is correct\n",
        "        expected_missing_count = np.array([0, 1, 1])\n",
        "        self.assertTrue(np.array_equal(missing_count, expected_missing_count))\n",
        "\n",
        "# Executa os testes unitários\n",
        "if __name__ == '__main__':\n",
        "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFWMBQG__cZ0",
        "outputId": "431e13c0-888f-4565-edc1-83b40651335c"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "........\n",
            "----------------------------------------------------------------------\n",
            "Ran 8 tests in 0.024s\n",
            "\n",
            "OK\n"
          ]
        }
      ]
    }
  ]
}