{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "\n",
        "class Dataset:\n",
        "    def __init__(self, X=None, y=None, feature_names=None, label_name=None):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.feature_names = feature_names\n",
        "        self.label_name = label_name\n",
        "        self.discrete_values = {}\n",
        "\n",
        "    def get_X(self):\n",
        "        return self.X\n",
        "\n",
        "    def get_y(self):\n",
        "        return self.y\n",
        "\n",
        "    def get_feature_names(self):\n",
        "        return self.feature_names\n",
        "\n",
        "    def get_label_name(self):\n",
        "        return self.label_name\n",
        "\n",
        "    def set_X(self, X):\n",
        "        self.X = X\n",
        "\n",
        "    def set_y(self, y):\n",
        "        self.y = y\n",
        "\n",
        "    def set_feature_names(self, feature_names):\n",
        "        self.feature_names = feature_names\n",
        "\n",
        "    def set_label_name(self, label_name):\n",
        "        self.label_name = label_name\n",
        "\n",
        "    def read_csv(self, filepath, delimiter=',', has_header=True):\n",
        "        with open(filepath, 'r') as file:\n",
        "            reader = csv.reader(file, delimiter=delimiter)\n",
        "            if has_header:\n",
        "                header = next(reader)\n",
        "                self.feature_names = header[:-1]\n",
        "                self.label_name = header[-1]\n",
        "            data = list(reader)\n",
        "        data = np.array(data, dtype=object)\n",
        "        self.X = data[:, :-1].astype(np.float64)\n",
        "        self.y = np.round(data[:, -1].astype(np.float64)).astype(np.int64)\n",
        "\n",
        "    def write_csv(self, filepath, delimiter=','):\n",
        "        data = np.column_stack((self.X, self.y))\n",
        "        with open(filepath, 'w') as file:\n",
        "            writer = csv.writer(file, delimiter=delimiter)\n",
        "            if self.feature_names is not None and self.label_name is not None:\n",
        "                writer.writerow(self.feature_names + [self.label_name])\n",
        "            writer.writerows(data)\n",
        "\n",
        "    def describe(self):\n",
        "        means = np.mean(self.X.astype(np.float64), axis=0)\n",
        "        stds = np.std(self.X.astype(np.float64), axis=0)\n",
        "        min_values = np.min(self.X.astype(np.float64), axis=0)\n",
        "        max_values = np.max(self.X.astype(np.float64), axis=0)\n",
        "\n",
        "        return means, stds, min_values, max_values\n",
        "\n",
        "    def find_missing_values(self):\n",
        "        return np.isnan(self.X.astype(np.float64))\n",
        "\n",
        "    def count_missing_values(self):\n",
        "        return np.sum(np.isnan(self.X.astype(np.float64)), axis=0)\n",
        "\n",
        "    def replace_missing_values(self, constant='mean'):\n",
        "        missing = self.find_missing_values()\n",
        "        for i in range(self.X.shape[1]):\n",
        "            if constant == 'mean':\n",
        "                replacement = np.nanmean(self.X[:, i].astype(np.float64))\n",
        "            elif constant == 'median':\n",
        "                replacement = np.nanmedian(self.X[:, i].astype(np.float64))\n",
        "            else:\n",
        "                replacement = constant\n",
        "            self.X[:, i][missing[:, i]] = replacement"
      ],
      "metadata": {
        "id": "Mgn0C2NY8wOy"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "\n",
        "# Load the iris dataset\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "# Extract the feature names and label name\n",
        "feature_names = iris.feature_names\n",
        "label_name = \"species\"\n",
        "\n",
        "# Create an instance of the Dataset class with the iris data\n",
        "dataset = Dataset(X=iris.data, y=iris.target, feature_names=feature_names, label_name=label_name)\n",
        "\n",
        "# Print some basic statistics\n",
        "means, stds, min_values, max_values = dataset.describe()\n",
        "print(\"Means:\", means)\n",
        "print(\"Standard deviations:\", stds)\n",
        "print(\"Minimum values:\", min_values)\n",
        "print(\"Maximum values:\", max_values)\n",
        "\n",
        "# Find and count missing values\n",
        "missing_values = dataset.find_missing_values()\n",
        "print(\"Missing values:\", missing_values)\n",
        "missing_count = dataset.count_missing_values()\n",
        "print(\"Missing values count:\", missing_count)\n",
        "\n",
        "# Write the dataset to a CSV file\n",
        "dataset.write_csv(\"iris.csv\")\n",
        "\n",
        "# Read the dataset from the CSV file\n",
        "dataset_from_csv = Dataset()\n",
        "dataset_from_csv.read_csv(\"iris.csv\", delimiter=',', has_header=True)\n",
        "\n",
        "# Print some statistics from the dataset read from the CSV file\n",
        "means, stds, min_values, max_values = dataset_from_csv.describe()\n",
        "print(\"Means (from CSV):\", means)\n",
        "print(\"Standard deviations (from CSV):\", stds)\n",
        "print(\"Minimum values (from CSV):\", min_values)\n",
        "print(\"Maximum values (from CSV):\", max_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFoAMIxY-wkw",
        "outputId": "d813bd78-760b-485f-ecbf-05b9be5dbfaa"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Means: [5.84333333 3.05733333 3.758      1.19933333]\n",
            "Standard deviations: [0.82530129 0.43441097 1.75940407 0.75969263]\n",
            "Minimum values: [4.3 2.  1.  0.1]\n",
            "Maximum values: [7.9 4.4 6.9 2.5]\n",
            "Missing values: [[False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]\n",
            " [False False False False]]\n",
            "Missing values count: [0 0 0 0]\n",
            "Means (from CSV): [5.84333333 3.05733333 3.758      1.19933333]\n",
            "Standard deviations (from CSV): [0.82530129 0.43441097 1.75940407 0.75969263]\n",
            "Minimum values (from CSV): [4.3 2.  1.  0.1]\n",
            "Maximum values (from CSV): [7.9 4.4 6.9 2.5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import unittest\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "import os\n",
        "import tempfile\n",
        "\n",
        "class TestDataset(unittest.TestCase):\n",
        "\n",
        "    def setUp(self):\n",
        "        iris = datasets.load_iris()\n",
        "        self.dataset = Dataset(X=iris.data, y=iris.target, feature_names=iris.feature_names, label_name=\"species\")\n",
        "\n",
        "    def test_getters_and_setters(self):\n",
        "        X = self.dataset.get_X()\n",
        "        y = self.dataset.get_y()\n",
        "        feature_names = self.dataset.get_feature_names()\n",
        "        label_name = self.dataset.get_label_name()\n",
        "\n",
        "        self.assertIsNotNone(X)\n",
        "        self.assertIsNotNone(y)\n",
        "        self.assertIsNotNone(feature_names)\n",
        "        self.assertIsNotNone(label_name)\n",
        "\n",
        "        self.dataset.set_X(np.array([[1, 2], [3, 4]]))\n",
        "        self.dataset.set_y(np.array([1, 0]))\n",
        "        self.dataset.set_feature_names(['a', 'b'])\n",
        "        self.dataset.set_label_name('c')\n",
        "\n",
        "        self.assertTrue(np.array_equal(self.dataset.get_X(), np.array([[1, 2], [3, 4]])))\n",
        "        self.assertTrue(np.array_equal(self.dataset.get_y(), np.array([1, 0])))\n",
        "        self.assertEqual(self.dataset.get_feature_names(), ['a', 'b'])\n",
        "        self.assertEqual(self.dataset.get_label_name(), 'c')\n",
        "\n",
        "    def test_read_write_csv(self):\n",
        "        self.dataset.write_csv(\"test_iris.csv\")\n",
        "        dataset_from_csv = Dataset()\n",
        "        dataset_from_csv.read_csv(\"test_iris.csv\", delimiter=',', has_header=True)\n",
        "\n",
        "        self.assertTrue(np.array_equal(self.dataset.get_X(), dataset_from_csv.get_X()))\n",
        "        self.assertTrue(np.array_equal(self.dataset.get_y(), dataset_from_csv.get_y()))\n",
        "        self.assertEqual(self.dataset.get_feature_names(), dataset_from_csv.get_feature_names())\n",
        "        self.assertEqual(self.dataset.get_label_name(), dataset_from_csv.get_label_name())\n",
        "\n",
        "    def test_write_csv(self):\n",
        "        # Create a temporary file\n",
        "        with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n",
        "            temp_filepath = temp_file.name\n",
        "\n",
        "        # Write the dataset to the temporary file\n",
        "        self.dataset.write_csv(temp_filepath)\n",
        "\n",
        "        # Read the dataset from the temporary file\n",
        "        dataset_from_csv = Dataset()\n",
        "        dataset_from_csv.read_csv(temp_filepath, delimiter=',', has_header=True)\n",
        "\n",
        "        # Compare the read dataset with the original dataset\n",
        "        self.assertTrue(np.array_equal(self.dataset.get_X(), dataset_from_csv.get_X()))\n",
        "        self.assertTrue(np.array_equal(self.dataset.get_y(), dataset_from_csv.get_y()))\n",
        "        self.assertEqual(self.dataset.get_feature_names(), dataset_from_csv.get_feature_names())\n",
        "        self.assertEqual(self.dataset.get_label_name(), dataset_from_csv.get_label_name())\n",
        "\n",
        "        # Remove the temporary file\n",
        "        os.remove(temp_filepath)\n",
        "\n",
        "    def test_describe(self):\n",
        "        means, stds, min_values, max_values = self.dataset.describe()\n",
        "\n",
        "        self.assertIsNotNone(means)\n",
        "        self.assertIsNotNone(stds)\n",
        "        self.assertIsNotNone(min_values)\n",
        "        self.assertIsNotNone(max_values)\n",
        "\n",
        "    def test_missing_values(self):\n",
        "        missing_values = self.dataset.find_missing_values()\n",
        "        self.assertIsNotNone(missing_values)\n",
        "        self.assertEqual(missing_values.shape, self.dataset.get_X().shape)\n",
        "\n",
        "        missing_count = self.dataset.count_missing_values()\n",
        "        self.assertIsNotNone(missing_count)\n",
        "        self.assertEqual(missing_count.shape, (self.dataset.get_X().shape[1],))\n",
        "\n",
        "    def test_replace_missing_values(self):\n",
        "        self.dataset.replace_missing_values(constant='mean')\n",
        "        missing_values = self.dataset.find_missing_values()\n",
        "        self.assertFalse(np.any(missing_values))\n",
        "\n",
        "    def test_find_missing_values(self):\n",
        "        # Create a dataset with some missing values\n",
        "        X = np.array([[1, np.nan, 3], [4, 5, np.nan], [7, 8, 9]])\n",
        "        y = np.array([0, 1, 2])\n",
        "        feature_names = ['a', 'b', 'c']\n",
        "        label_name = 'd'\n",
        "        dataset_with_missing_values = Dataset(X=X, y=y, feature_names=feature_names, label_name=label_name)\n",
        "\n",
        "        # Find missing values\n",
        "        missing_values = dataset_with_missing_values.find_missing_values()\n",
        "\n",
        "        # Check if the missing values are correctly identified\n",
        "        expected_missing_values = np.array([[False, True, False], [False, False, True], [False, False, False]])\n",
        "        self.assertTrue(np.array_equal(missing_values, expected_missing_values))\n",
        "\n",
        "    def test_count_missing_values(self):\n",
        "        # Create a dataset with some missing values\n",
        "        X = np.array([[1, np.nan, 3], [4, 5, np.nan], [7, 8, 9]])\n",
        "        y = np.array([0, 1, 2])\n",
        "        feature_names = ['a', 'b', 'c']\n",
        "        label_name = 'd'\n",
        "        dataset_with_missing_values = Dataset(X=X, y=y, feature_names=feature_names, label_name=label_name)\n",
        "\n",
        "        # Count missing values\n",
        "        missing_count = dataset_with_missing_values.count_missing_values()\n",
        "\n",
        "        # Check if the count of missing values is correct\n",
        "        expected_missing_count = np.array([0, 1, 1])\n",
        "        self.assertTrue(np.array_equal(missing_count, expected_missing_count))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFWMBQG__cZ0",
        "outputId": "7b14d96c-3ff4-434a-b3d7-441993b05309"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "........\n",
            "----------------------------------------------------------------------\n",
            "Ran 8 tests in 0.028s\n",
            "\n",
            "OK\n"
          ]
        }
      ]
    }
  ]
}