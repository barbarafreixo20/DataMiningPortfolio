{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código implementa uma decision tree, usando diferentes critérios para escolher os melhores atributos e diferentes métodos para resolver conflitos, fazer Pre-Prunning e Pos-Prunning.\n",
    "\n",
    "Os critérios de seleção de atributos disponíveis são  Entropy, Gini Index e Gain Ratio, enquanto os métodos de resolução de conflitos são Poda, Majority voting e Class threshold.\n",
    "\n",
    "A pre-Prunning pode ser feita com base em Size, Maximum Depth ou Independence, enquanto a pos-Prunning pode ser feita com base em  Pessimistic error prunning ou Reduced error prunning.\n",
    "\n",
    "O código implementa a construção da árvore de decisão recursivamente e, em cada nó, o melhor atributo é escolhido para dividir os dados, de acordo com o critério selecionado. A impureza antes e depois da divisão é calculada e o ganho de informação é obtido a partir desses valores. Se o ganho de informação não atingir um determinado threshold, a folha é criada para esse nó. Se um dos subconjuntos resultantes da divisão for vazio, a folha é criada para esse nó."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Optional\n",
    "\n",
    "def _gini( y_pred):\n",
    "    _, counts = np.unique(y_pred, return_counts=True)\n",
    "    probs = counts / len(y_pred)\n",
    "    return 1 - np.sum(probs ** 2)\n",
    "\n",
    "\n",
    "def _entropy(y):\n",
    "    _, counts = np.unique(y, return_counts=True)\n",
    "    probs = counts / len(y)\n",
    "    return -np.sum(probs * np.log2(probs))\n",
    "\n",
    "\n",
    "def _split(feature, y, threshold):\n",
    "    left_indices = np.where(feature <= threshold)[0]\n",
    "    right_indices = np.where(feature > threshold)[0]\n",
    "    return left_indices, right_indices\n",
    "\n",
    "\n",
    "def gain_ratio(X, y, feature_indices):\n",
    "    base_impurity = _entropy(y)\n",
    "    max_gain_ratio = 0\n",
    "    best_feature_index = None\n",
    "    best_threshold = None\n",
    "    for feature_index in feature_indices:\n",
    "        values = np.unique(X[:, feature_index])\n",
    "        for threshold in values:\n",
    "            left_indices, right_indices = _split(X[:, feature_index], y, threshold)\n",
    "            left_ratio = len(left_indices) / len(X)\n",
    "            right_ratio = len(right_indices) / len(X)\n",
    "            split_impurity = left_ratio * _entropy(y[left_indices]) + right_ratio * _entropy(y[right_indices])\n",
    "            information_gain = base_impurity - split_impurity\n",
    "            split_info = -left_ratio * np.log2(left_ratio) - right_ratio * np.log2(right_ratio)\n",
    "            gain_r = information_gain / split_info if split_info != 0 else 0\n",
    "            if gain_r > max_gain_ratio:\n",
    "                max_gain_ratio = gain_r\n",
    "                best_feature_index = feature_index\n",
    "                best_threshold = threshold\n",
    "    return (best_feature_index, best_threshold) if max_gain_ratio > 0 else None\n",
    "\n",
    "\n",
    "def select_best_split_entropy(X, y, feature_indices):\n",
    "    best_feature_index, best_threshold, best_info_gain = None, None, -float(\"inf\")\n",
    "\n",
    "    for feature_index in feature_indices:\n",
    "        thresholds = np.unique(X[:, feature_index])\n",
    "        for threshold in thresholds:\n",
    "            left_indices = X[:, feature_index] <= threshold\n",
    "            right_indices = X[:, feature_index] > threshold\n",
    "            H_y_x = (np.sum(left_indices) / len(y)) * _entropy(y[left_indices]) + \\\n",
    "                    (np.sum(right_indices) / len(y)) * _entropy(y[right_indices])\n",
    "            info_gain = _entropy(y) - H_y_x\n",
    "            if info_gain > best_info_gain:\n",
    "                best_feature_index = feature_index\n",
    "                best_threshold = threshold\n",
    "                best_info_gain = info_gain\n",
    "\n",
    "    return best_feature_index, best_threshold\n",
    "\n",
    "\n",
    "def select_best_split_gini_index(X, y, feature_indices):\n",
    "    best_feature_index = None\n",
    "    best_threshold = None\n",
    "    best_gini_index = float('inf')\n",
    "    for feature_index in feature_indices:\n",
    "        unique_thresholds = np.unique(X[:, feature_index])\n",
    "        for threshold in unique_thresholds:\n",
    "            left_indices = X[:, feature_index] <= threshold\n",
    "            right_indices = X[:, feature_index] > threshold\n",
    "            if len(left_indices) == 0 or len(right_indices) == 0:\n",
    "                continue\n",
    "            left_gini = _gini(y[left_indices])\n",
    "            right_gini = _gini(y[right_indices])\n",
    "            current_gini_index = (left_gini * np.sum(left_indices) + right_gini * np.sum(right_indices)) / len(y)\n",
    "            if current_gini_index < best_gini_index:\n",
    "                best_gini_index = current_gini_index\n",
    "                best_feature_index = feature_index\n",
    "                best_threshold = threshold\n",
    "    return best_feature_index, best_threshold\n",
    "\n",
    "\n",
    "def split_information(n_left, n_right):\n",
    "    n_total = n_left + n_right\n",
    "    p_left = n_left / n_total\n",
    "    p_right = n_right / n_total\n",
    "    if p_left == 0 or p_right == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return - p_left * np.log2(p_left) - p_right * np.log2(p_right)\n",
    "\n",
    "\n",
    "def calculate_gain_ratio(y, left_indices, right_indices):\n",
    "    entropy_before_split = _entropy(y)\n",
    "\n",
    "    left_entropy = _entropy(y[left_indices])\n",
    "    right_entropy = _entropy(y[right_indices])\n",
    "    n_instances = len(y)\n",
    "    n_left = len(left_indices)\n",
    "    n_right = n_instances - n_left\n",
    "    weighted_avg_entropy = (n_left / n_instances) * left_entropy + (n_right / n_instances) * right_entropy\n",
    "\n",
    "    split_info = split_information(n_left, n_right)\n",
    "\n",
    "    if split_info == 0:\n",
    "        gain_ratio = 0\n",
    "    else:\n",
    "        gain_ratio = (entropy_before_split - weighted_avg_entropy) / split_info\n",
    "\n",
    "    return gain_ratio\n",
    "\n",
    "\n",
    "def select_best_split_gain_ratio(X, y, feature_indices):\n",
    "    best_feature_index, best_threshold, max_gain_ratio = None, None, 0.0\n",
    "    H_y = _entropy(y)\n",
    "    for feature_index in feature_indices:\n",
    "        thresholds = np.unique(X[:, feature_index])\n",
    "        for threshold in thresholds:\n",
    "            left_indices = np.where(X[:, feature_index] <= threshold)[0].astype(int)\n",
    "            right_indices = np.where(X[:, feature_index] > threshold)[0].astype(int)\n",
    "            if len(left_indices) == 0 or len(right_indices) == 0:\n",
    "                continue\n",
    "            H_y_x = (len(left_indices) / len(y)) * _entropy(y[left_indices]) + \\\n",
    "                    (len(right_indices) / len(y)) * _entropy(y[right_indices])\n",
    "            split_info = split_information(len(left_indices), len(right_indices))\n",
    "            gain_ratio = (H_y - H_y_x) / split_info if split_info != 0 else 0\n",
    "            if gain_ratio > max_gain_ratio:\n",
    "                best_feature_index, best_threshold, max_gain_ratio = feature_index, threshold, gain_ratio\n",
    "    return best_feature_index, best_threshold\n",
    "\n",
    "\n",
    "def building_tree(X, y, feature_indices, max_depth=None, min_samples_leaf=1, impurity_measure=\"entropy\"):\n",
    "    if len(np.unique(y)) == 1:\n",
    "        return Node(label=y[0])\n",
    "    if max_depth is not None and max_depth == 0:\n",
    "        return Node(label=np.argmax(np.bincount(y)))\n",
    "    if len(X) < min_samples_leaf:\n",
    "        return Node(label=np.argmax(np.bincount(y)))\n",
    "    if impurity_measure == \"entropy\":\n",
    "        impurity_func = _entropy\n",
    "        best_criteria_func = select_best_split_entropy\n",
    "    elif impurity_measure == \"gini_index\":\n",
    "        impurity_func = _gini\n",
    "        best_criteria_func = select_best_split_gini_index\n",
    "    elif impurity_measure == \"gain_ratio\":\n",
    "        impurity_func = _entropy\n",
    "        best_criteria_func = select_best_split_gain_ratio\n",
    "    else:\n",
    "        raise ValueError(\"Invalid impurity measure specified\")\n",
    "    best_feature_index, best_threshold = best_criteria_func(X, y, feature_indices)\n",
    "    if best_feature_index is None:\n",
    "        return Node(label=np.argmax(np.bincount(y)))\n",
    "    left_indices = np.where(X[:, best_feature_index] <= best_threshold)[0].astype(int)\n",
    "    right_indices = np.where(X[:, best_feature_index] > best_threshold)[0].astype(int)\n",
    "    left_child = building_tree(X[left_indices], y[left_indices], feature_indices, max_depth=max_depth-1 if max_depth is not None else None, min_samples_leaf=min_samples_leaf, impurity_measure=impurity_measure)\n",
    "    right_child = building_tree(X[right_indices], y[right_indices], feature_indices, max_depth=max_depth-1 if max_depth is not None else None, min_samples_leaf=min_samples_leaf, impurity_measure=impurity_measure)\n",
    "    return Node(split_feature=best_feature_index, split_threshold=best_threshold, left_child=left_child,\n",
    "                right_child=right_child, impurity=impurity_func(y))\n",
    "\n",
    "\n",
    "def prunning(node, X, y, prune_method, threshold=None):\n",
    "    if node.label is not None:\n",
    "        return node\n",
    "    \n",
    "    node.left_child = prunning(node.left_child, X, y, prune_method, threshold)\n",
    "    node.right_child = prunning(node.right_child, X, y, prune_method, threshold)\n",
    "    \n",
    "    left_label = None\n",
    "    right_label = None\n",
    "    \n",
    "    if node.left_child.label is not None and node.right_child.label is not None:\n",
    "        if prune_method == \"majority_voting\":\n",
    "            left_label = node.left_child.label\n",
    "            right_label = node.right_child.label\n",
    "            \n",
    "            if np.sum(y == left_label) > np.sum(y == right_label):\n",
    "                node.label = left_label\n",
    "            else:\n",
    "                node.label = right_label\n",
    "        elif prune_method == \"class_threshold\":\n",
    "            node_samples = len(y)\n",
    "            \n",
    "            if node.left_child.label is not None:\n",
    "                left_label = node.left_child.label\n",
    "                left_samples = len(np.where(y[node.left_child.indices] == left_label)[0])\n",
    "            else:\n",
    "                left_samples = 0\n",
    "                \n",
    "            if node.right_child.label is not None:\n",
    "                right_label = node.right_child.label\n",
    "                right_samples = len(np.where(y[node.right_child.indices] == right_label)[0])\n",
    "            else:\n",
    "                right_samples = 0\n",
    "                \n",
    "            if (left_samples / node_samples >= threshold) and (right_samples / node_samples >= threshold):\n",
    "                node.label = None\n",
    "                \n",
    "    return node\n",
    "\n",
    "\n",
    "def predict(X, node):\n",
    "    y_pred = []\n",
    "    for x in X:\n",
    "        current_node = node\n",
    "        while current_node.label is None:\n",
    "            if x[current_node.split_feature] <= current_node.split_threshold:\n",
    "                current_node = current_node.left_child\n",
    "            else:\n",
    "                current_node = current_node.right_child\n",
    "        y_pred.append(current_node.label)\n",
    "    return np.array(y_pred)\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, \n",
    "                 max_depth: Optional[int] = None,\n",
    "                 min_samples_leaf: int = 1,\n",
    "                 impurity_measure: str = \"entropy\",\n",
    "                 attribute_selection: str = \"gain_ratio\",\n",
    "                 prune_method: Optional[str] = None,\n",
    "                 threshold: Optional[float] = None) -> None:\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.impurity_measure = impurity_measure\n",
    "        self.attribute_selection = attribute_selection\n",
    "        self.prune_method = prune_method\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> \"DecisionTree\":\n",
    "        self.n_features_ = X.shape[1]\n",
    "        self.feature_indices_ = np.arange(self.n_features_)\n",
    "        if self.attribute_selection == \"random\":\n",
    "            self.feature_indices_ = np.random.choice(self.feature_indices_, size=int(np.sqrt(self.n_features_)),\n",
    "                                                     replace=False)\n",
    "        self.root_ = building_tree(X, y, self.feature_indices_, self.max_depth, self.min_samples_leaf,\n",
    "                                self.impurity_measure)\n",
    "        if self.prune_method is not None:\n",
    "            self.root_ = prunning(self.root_, X, y, self.prune_method, self.threshold)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        return predict(X, self.root_)\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.split_feature = kwargs.get('split_feature', None)\n",
    "        self.split_threshold = kwargs.get('split_threshold', None)\n",
    "        self.left_child = kwargs.get('left_child', None)\n",
    "        self.right_child = kwargs.get('right_child', None)\n",
    "        self.label = kwargs.get('label', None)\n",
    "        self.impurity = kwargs.get('impurity', None)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exemplos de Aplicação**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.93\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "value = DecisionTree(max_depth=10, min_samples_leaf=20, impurity_measure=\"entropy\",\n",
    "                             attribute_selection=\"gain_ratio\", prune_method=\"reduced_error\", threshold=0.2)\n",
    "\n",
    "value.fit(X_train, y_train)\n",
    "\n",
    "y_pred = value.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.86\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X, y = load_digits(return_X_y=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "value = DecisionTree(max_depth=10, min_samples_leaf=20, impurity_measure=\"entropy\",\n",
    "                             attribute_selection=\"gain_ratio\", prune_method=\"reduced_error\", threshold=0.2)\n",
    "\n",
    "value.fit(X_train, y_train)\n",
    "\n",
    "y_pred = value.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
