{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trabalho realizado por: Bárbara Freixo, PG49169\n",
    "\n",
    "Esta implementação implementa uma classe Dataset e uma classe MLP para classificação binária utilizando a função de ativação sigmoide. A classe MLP define métodos para inicializar a rede neuronal, definir pesos, prever saídas, calcular a função custo, construir o modelo e normalizar dados. A classe Dataset define métodos para ler e escrever conjuntos de dados, obter atributos e rótulos, dividir conjuntos em treino e teste e processar rótulos binários. A função funcao_sigmoid(x) é uma implementação da função de ativação sigmoide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import optimize\n",
    "\n",
    "class MLP:\n",
    "    \n",
    "    # Inicializa a classe MLP\n",
    "    def __init__(self, conjunto_dados, nos_ocultos = 2, normalizar = False):\n",
    "        self.Atributos, self.Rotulos = conjunto_dados.getXy()\n",
    "        # Adiciona uma coluna de 1s para o bias\n",
    "        self.Atributos = np.hstack((np.ones([self.Atributos.shape[0], 1]), self.Atributos))\n",
    "        \n",
    "        self.n = nos_ocultos\n",
    "        self.P1 = np.zeros([nos_ocultos, self.Atributos.shape[1]])\n",
    "        self.P2 = np.zeros([1, nos_ocultos + 1])\n",
    "        \n",
    "        # Normaliza os dados se normalizar=True\n",
    "        if normalizar:\n",
    "            self.normalizar_dados()\n",
    "        else:\n",
    "            self.normalizado = False\n",
    "\n",
    "    # Define os pesos das camadas\n",
    "    def definir_pesos(self, p1, p2):\n",
    "        self.P1 = p1\n",
    "        self.P2 = p2   \n",
    "\n",
    "    # Realiza a previsão para uma única instância\n",
    "    def prever(self, instancia):\n",
    "        x = np.empty([self.Atributos.shape[1]])        \n",
    "        x[0] = 1\n",
    "        x[1:] = np.array(instancia[:self.Atributos.shape[1] - 1])\n",
    "        \n",
    "        # Normaliza a instância se os dados estiverem normalizados\n",
    "        if self.normalizado:\n",
    "            if np.all(self.desvio_padrao != 0): \n",
    "                x[1:] = (x[1:] - self.media) / self.desvio_padrao\n",
    "            else: x[1:] = (x[1:] - self.media)\n",
    "        \n",
    "        # Realiza a previsão\n",
    "        z2 = np.dot(self.P1, x)\n",
    "        a2 = np.empty([z2.shape[0] + 1])\n",
    "        a2[0] = 1\n",
    "        a2[1:] = funcao_sigmoid(z2)\n",
    "        z3 = np.dot(self.P2, a2)\n",
    "                        \n",
    "        return funcao_sigmoid(z3)\n",
    "\n",
    "    # Calcula a função de custo\n",
    "    def funcao_custo(self, pesos = None):\n",
    "        if pesos is not None:\n",
    "            self.P1 = pesos[:self.n * self.Atributos.shape[1]].reshape([self.n, self.Atributos.shape[1]])\n",
    "            self.P2 = pesos[self.n * self.Atributos.shape[1]:].reshape([1, self.n + 1])\n",
    "        \n",
    "        m = self.Atributos.shape[0]\n",
    "        z2 = np.dot(self.Atributos, self.P1.T)\n",
    "        a2 = np.hstack((np.ones([z2.shape[0], 1]), funcao_sigmoid(z2)))\n",
    "        z3 = np.dot(a2, self.P2.T)\n",
    "        previsoes = funcao_sigmoid(z3)\n",
    "        erro_quadratico = (previsoes - self.Rotulos.reshape(m, 1)) ** 2\n",
    "        resultado = np.sum(erro_quadratico) / (2 * m)\n",
    "        return resultado\n",
    "\n",
    "    # Constrói o modelo MLP\n",
    "    def construir_modelo(self):\n",
    "        tamanho = self.n * self.Atributos.shape[1] + self.n + 1\n",
    "        pesos_iniciais = np.random.rand(tamanho)        \n",
    "        resultado = optimize.minimize(lambda w: self.funcao_custo(w), pesos_iniciais, method='BFGS', \n",
    "                                    options={\"maxiter\":1000, \"disp\":False} )\n",
    "        pesos = resultado.x\n",
    "        self.P1 = pesos[:self.n * self.Atributos.shape[1]].reshape([self.n, self.Atributos.shape[1]])\n",
    "        self.P2 = pesos[self.n * self.Atributos.shape[1]:].reshape([1, self.n + 1])\n",
    "\n",
    "    # Normaliza os dados\n",
    "    def normalizar_dados(self):\n",
    "          self.media = np.mean(self.Atributos[:, 1:], axis=0)\n",
    "          self.Atributos[:, 1:] = self.Atributos[:, 1:] - self.media\n",
    "          self.desvio_padrao = np.std(self.Atributos[:, 1:], axis=0)\n",
    "          self.Atributos[:, 1:] = self.Atributos[:, 1:] / self.desvio_padrao\n",
    "          self.normalizado = True\n",
    "\n",
    "def funcao_sigmoid(x):\n",
    "  return (1 / (np.exp(-x)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    \n",
    "    # constructor\n",
    "    def __init__(self, filename = None, X = None, Y = None):\n",
    "        if filename is not None:\n",
    "            self.readDataset(filename)\n",
    "        elif X is not None and Y is not None:\n",
    "            self.X = X\n",
    "            self.Y = Y\n",
    "        else:\n",
    "            self.X = None\n",
    "            self.Y = None\n",
    "        \n",
    "    def readDataset(self, filename, sep = \",\"):\n",
    "        data = np.genfromtxt(filename, delimiter=sep)\n",
    "        self.X = data[:,0:-1]\n",
    "        self.Y = data[:,-1]\n",
    "        \n",
    "    def writeDataset(self, filename, sep = \",\"):\n",
    "        fullds = np.hstack( (self.X, self.Y.reshape(len(self.Y),1)))\n",
    "        np.savetxt(filename, fullds, delimiter = sep)\n",
    "        \n",
    "    def getXy (self):\n",
    "        return self.X, self.Y\n",
    "    \n",
    "    def train_test_split(self, p = 0.7):\n",
    "        from random import shuffle\n",
    "        ninst = self.X.shape[0]\n",
    "        inst_indexes = np.array(range(ninst))\n",
    "        ntr = (int)(p*ninst)\n",
    "        shuffle(inst_indexes)\n",
    "        tr_indexes = inst_indexes[1:ntr]\n",
    "        tst_indexes = inst_indexes[ntr+1:]\n",
    "        Xtr = self.X[tr_indexes,]\n",
    "        ytr = self.Y[tr_indexes]\n",
    "        Xts = self.X[tst_indexes,]\n",
    "        yts = self.Y[tst_indexes]\n",
    "        return (Xtr, ytr, Xts, yts) \n",
    "    \n",
    "    def process_binary_y(self):\n",
    "        y_values = np.unique(self.Y)\n",
    "        if len(y_values) == 2:\n",
    "            self.Y = np.where(self.Y == y_values[0], 0, 1)\n",
    "        else:\n",
    "            print(\"Non binary\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testes e exemplos para o algoritmo implementado"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo de uso do código"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta implementação é um exemplo de como usar as classes implementadas anteriormente. Primeiro, carrega o conjunto de dados Iris e usa apenas as primeiras 100 amostras para criar um objeto Dataset. Em seguida, o conjunto de dados é dividido num conjunto de treino e num conjunto de teste usando o método train_test_split. Depois, é criado um conjunto de dados de treino para o MLP e o modelo MLP é criado e treinado com os dados de treino usando a classe MLP. Por fim, é feita a previsão com o modelo treinado usando os dados de teste e é calculada a acurácia do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instância de teste: [5.1 3.3 1.7 0.5], Saída prevista: [0.0006271], Saída real: 0\n",
      "Instância de teste: [6.3 2.5 4.9 1.5], Saída prevista: [0.99988365], Saída real: 1\n",
      "Instância de teste: [5.4 3.4 1.7 0.2], Saída prevista: [0.00062149], Saída real: 0\n",
      "Instância de teste: [5.7 3.  4.2 1.2], Saída prevista: [0.99977598], Saída real: 1\n",
      "Instância de teste: [5.6 2.9 3.6 1.3], Saída prevista: [0.99967446], Saída real: 1\n",
      "Instância de teste: [6.8 2.8 4.8 1.4], Saída prevista: [0.99989143], Saída real: 1\n",
      "Instância de teste: [5.8 2.7 3.9 1.2], Saída prevista: [0.99977068], Saída real: 1\n",
      "Instância de teste: [5.1 3.7 1.5 0.4], Saída prevista: [0.00049809], Saída real: 0\n",
      "Instância de teste: [5.6 3.  4.1 1.3], Saída prevista: [0.99976587], Saída real: 1\n",
      "Instância de teste: [6.  2.2 4.  1. ], Saída prevista: [0.9997708], Saída real: 1\n",
      "Instância de teste: [5.5 3.5 1.3 0.2], Saída prevista: [0.00057618], Saída real: 0\n",
      "Instância de teste: [5.2 4.1 1.5 0.1], Saída prevista: [0.0003893], Saída real: 0\n",
      "Instância de teste: [4.6 3.2 1.4 0.2], Saída prevista: [0.0001464], Saída real: 0\n",
      "Instância de teste: [5.  3.  1.6 0.2], Saída prevista: [0.00024663], Saída real: 0\n",
      "Instância de teste: [4.6 3.1 1.5 0.2], Saída prevista: [0.00014856], Saída real: 0\n",
      "Instância de teste: [5.7 4.4 1.5 0.4], Saída prevista: [0.00248656], Saída real: 0\n",
      "Instância de teste: [6.7 3.1 4.4 1.4], Saída prevista: [0.99988784], Saída real: 1\n",
      "Instância de teste: [5.  3.3 1.4 0.2], Saída prevista: [0.00023998], Saída real: 0\n",
      "Instância de teste: [4.8 3.1 1.6 0.2], Saída prevista: [0.00019273], Saída real: 0\n",
      "Instância de teste: [5.8 2.6 4.  1.2], Saída prevista: [0.99978126], Saída real: 1\n",
      "Instância de teste: [6.3 3.3 4.7 1.6], Saída prevista: [0.99988697], Saída real: 1\n",
      "Instância de teste: [5.1 3.5 1.4 0.3], Saída prevista: [0.00035488], Saída real: 0\n",
      "Instância de teste: [6.1 2.9 4.7 1.4], Saída prevista: [0.99987263], Saída real: 1\n",
      "Instância de teste: [6.4 2.9 4.3 1.3], Saída prevista: [0.99987388], Saída real: 1\n",
      "Instância de teste: [5.4 3.9 1.3 0.4], Saída prevista: [0.00085796], Saída real: 0\n",
      "Instância de teste: [5.6 3.  4.5 1.5], Saída prevista: [0.99983833], Saída real: 1\n",
      "Instância de teste: [4.3 3.  1.1 0.1], Saída prevista: [9.84322475e-05], Saída real: 0\n",
      "Instância de teste: [5.  3.2 1.2 0.2], Saída prevista: [0.00021048], Saída real: 0\n",
      "Instância de teste: [4.9 3.1 1.5 0.1], Saída prevista: [0.00018237], Saída real: 0\n",
      "Acurácia: 100.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Carrega o dataset Iris do sklearn\n",
    "iris = load_iris()\n",
    "X = iris.data[:100]  # Usamos apenas as primeiras 100 amostras (setosa e versicolor)\n",
    "y = iris.target[:100]  # Convertido automaticamente para 0 (setosa) e 1 (versicolor)\n",
    "\n",
    "# Cria um objeto Dataset\n",
    "dataset = Dataset(X=X, Y=y)\n",
    "\n",
    "# Divide o conjunto de dados em treino e teste\n",
    "X_train, y_train, X_test, y_test = dataset.train_test_split(p=0.7)\n",
    "\n",
    "# Cria um conjunto de dados de treino para o MLP\n",
    "train_dataset = Dataset(X=X_train, Y=y_train)\n",
    "\n",
    "# Cria e treina o modelo MLP\n",
    "mlp = MLP(conjunto_dados=train_dataset, nos_ocultos=5, normalizar=True)\n",
    "mlp.construir_modelo()\n",
    "\n",
    "# Faz previsões com o modelo treinado\n",
    "correct = 0\n",
    "for i in range(len(X_test)):\n",
    "    test_instance = X_test[i]\n",
    "    prediction = mlp.prever(test_instance)\n",
    "    print(f\"Instância de teste: {test_instance}, Saída prevista: {prediction}, Saída real: {y_test[i]}\")\n",
    "    if round(prediction.item()) == y_test[i]:\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct / len(X_test)\n",
    "print(f\"Acurácia: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testes \"Unittest\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi realizado um teste utilizando o unittest para testar a implementação do MLP. Temos então o seguinte teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
