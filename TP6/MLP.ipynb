{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trabalho realizado por: Bárbara Freixo, PG49169\n",
    "\n",
    "Esta implementação implementa uma classe Dataset e uma classe MLP para classificação binária utilizando a função de ativação sigmoide. A classe MLP define métodos para inicializar a rede neuronal, definir pesos, prever saídas, calcular a função custo, construir o modelo e normalizar dados. A classe Dataset define métodos para ler e escrever conjuntos de dados, obter atributos e rótulos, dividir conjuntos em treino e teste e processar rótulos binários. A função funcao_sigmoid(x) é uma implementação da função de ativação sigmoide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import optimize\n",
    "\n",
    "class MLP:\n",
    "    \n",
    "    # Inicializa a classe MLP\n",
    "    def __init__(self, conjunto_dados, nos_ocultos = 2, normalizar = False):\n",
    "        self.Atributos, self.Rotulos = conjunto_dados.getXy()\n",
    "        # Adiciona uma coluna de 1s para o bias\n",
    "        self.Atributos = np.hstack((np.ones([self.Atributos.shape[0], 1]), self.Atributos))\n",
    "        \n",
    "        self.n = nos_ocultos\n",
    "        self.P1 = np.zeros([nos_ocultos, self.Atributos.shape[1]])\n",
    "        self.P2 = np.zeros([1, nos_ocultos + 1])\n",
    "        \n",
    "        # Normaliza os dados se normalizar=True\n",
    "        if normalizar:\n",
    "            self.normalizar_dados()\n",
    "        else:\n",
    "            self.normalizado = False\n",
    "\n",
    "    # Define os pesos das camadas\n",
    "    def definir_pesos(self, p1, p2):\n",
    "        self.P1 = p1\n",
    "        self.P2 = p2   \n",
    "\n",
    "    # Realiza a previsão para uma única instância\n",
    "    def prever(self, instancia):\n",
    "        x = np.empty([self.Atributos.shape[1]])        \n",
    "        x[0] = 1\n",
    "        x[1:] = np.array(instancia[:self.Atributos.shape[1] - 1])\n",
    "        \n",
    "        # Normaliza a instância se os dados estiverem normalizados\n",
    "        if self.normalizado:\n",
    "            if np.all(self.desvio_padrao != 0): \n",
    "                x[1:] = (x[1:] - self.media) / self.desvio_padrao\n",
    "            else: x[1:] = (x[1:] - self.media)\n",
    "        \n",
    "        # Realiza a previsão\n",
    "        z2 = np.dot(self.P1, x)\n",
    "        a2 = np.empty([z2.shape[0] + 1])\n",
    "        a2[0] = 1\n",
    "        a2[1:] = funcao_sigmoid(z2)\n",
    "        z3 = np.dot(self.P2, a2)\n",
    "                        \n",
    "        return funcao_sigmoid(z3)\n",
    "\n",
    "    # Calcula a função de custo\n",
    "    def funcao_custo(self, pesos = None):\n",
    "        if pesos is not None:\n",
    "            self.P1 = pesos[:self.n * self.Atributos.shape[1]].reshape([self.n, self.Atributos.shape[1]])\n",
    "            self.P2 = pesos[self.n * self.Atributos.shape[1]:].reshape([1, self.n + 1])\n",
    "        \n",
    "        m = self.Atributos.shape[0]\n",
    "        z2 = np.dot(self.Atributos, self.P1.T)\n",
    "        a2 = np.hstack((np.ones([z2.shape[0], 1]), funcao_sigmoid(z2)))\n",
    "        z3 = np.dot(a2, self.P2.T)\n",
    "        previsoes = funcao_sigmoid(z3)\n",
    "        erro_quadratico = (previsoes - self.Rotulos.reshape(m, 1)) ** 2\n",
    "        resultado = np.sum(erro_quadratico) / (2 * m)\n",
    "        return resultado\n",
    "\n",
    "    # Constrói o modelo MLP\n",
    "    def construir_modelo(self):\n",
    "        tamanho = self.n * self.Atributos.shape[1] + self.n + 1\n",
    "        pesos_iniciais = np.random.rand(tamanho)        \n",
    "        resultado = optimize.minimize(lambda w: self.funcao_custo(w), pesos_iniciais, method='BFGS', \n",
    "                                    options={\"maxiter\":1000, \"disp\":False} )\n",
    "        pesos = resultado.x\n",
    "        self.P1 = pesos[:self.n * self.Atributos.shape[1]].reshape([self.n, self.Atributos.shape[1]])\n",
    "        self.P2 = pesos[self.n * self.Atributos.shape[1]:].reshape([1, self.n + 1])\n",
    "\n",
    "    # Normaliza os dados\n",
    "    def normalizar_dados(self):\n",
    "          self.media = np.mean(self.Atributos[:, 1:], axis=0)\n",
    "          self.Atributos[:, 1:] = self.Atributos[:, 1:] - self.media\n",
    "          self.desvio_padrao = np.std(self.Atributos[:, 1:], axis=0)\n",
    "          self.Atributos[:, 1:] = self.Atributos[:, 1:] / self.desvio_padrao\n",
    "          self.normalizado = True\n",
    "\n",
    "def funcao_sigmoid(x):\n",
    "  return (1 / (np.exp(-x)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    \n",
    "    # constructor\n",
    "    def __init__(self, filename = None, X = None, Y = None):\n",
    "        if filename is not None:\n",
    "            self.readDataset(filename)\n",
    "        elif X is not None and Y is not None:\n",
    "            self.X = X\n",
    "            self.Y = Y\n",
    "        else:\n",
    "            self.X = None\n",
    "            self.Y = None\n",
    "        \n",
    "    def readDataset(self, filename, sep = \",\"):\n",
    "        data = np.genfromtxt(filename, delimiter=sep)\n",
    "        self.X = data[:,0:-1]\n",
    "        self.Y = data[:,-1]\n",
    "        \n",
    "    def writeDataset(self, filename, sep = \",\"):\n",
    "        fullds = np.hstack( (self.X, self.Y.reshape(len(self.Y),1)))\n",
    "        np.savetxt(filename, fullds, delimiter = sep)\n",
    "        \n",
    "    def getXy (self):\n",
    "        return self.X, self.Y\n",
    "    \n",
    "    def train_test_split(self, p = 0.7):\n",
    "        from random import shuffle\n",
    "        ninst = self.X.shape[0]\n",
    "        inst_indexes = np.array(range(ninst))\n",
    "        ntr = (int)(p*ninst)\n",
    "        shuffle(inst_indexes)\n",
    "        tr_indexes = inst_indexes[1:ntr]\n",
    "        tst_indexes = inst_indexes[ntr+1:]\n",
    "        Xtr = self.X[tr_indexes,]\n",
    "        ytr = self.Y[tr_indexes]\n",
    "        Xts = self.X[tst_indexes,]\n",
    "        yts = self.Y[tst_indexes]\n",
    "        return (Xtr, ytr, Xts, yts) \n",
    "    \n",
    "    def process_binary_y(self):\n",
    "        y_values = np.unique(self.Y)\n",
    "        if len(y_values) == 2:\n",
    "            self.Y = np.where(self.Y == y_values[0], 0, 1)\n",
    "        else:\n",
    "            print(\"Non binary\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testes e exemplos para o algoritmo implementado"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo de uso do código"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta implementação é um exemplo de como usar as classes implementadas anteriormente. Primeiro, carrega o conjunto de dados Iris e usa apenas as primeiras 100 amostras para criar um objeto Dataset. Em seguida, o conjunto de dados é dividido num conjunto de treino e num conjunto de teste usando o método train_test_split. Depois, é criado um conjunto de dados de treino para o MLP e o modelo MLP é criado e treinado com os dados de treino usando a classe MLP. Por fim, é feita a previsão com o modelo treinado usando os dados de teste e é calculada a acurácia do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instância de teste: [5.5 2.5 4.  1.3], Saída prevista: [0.99640732], Saída real: 1\n",
      "Instância de teste: [6.6 3.  4.4 1.4], Saída prevista: [0.99641298], Saída real: 1\n",
      "Instância de teste: [4.8 3.  1.4 0.3], Saída prevista: [0.00615194], Saída real: 0\n",
      "Instância de teste: [4.9 2.4 3.3 1. ], Saída prevista: [0.98785893], Saída real: 1\n",
      "Instância de teste: [5.4 3.9 1.7 0.4], Saída prevista: [0.0057354], Saída real: 0\n",
      "Instância de teste: [6.2 2.2 4.5 1.5], Saída prevista: [0.99660345], Saída real: 1\n",
      "Instância de teste: [6.7 3.  5.  1.7], Saída prevista: [0.99643431], Saída real: 1\n",
      "Instância de teste: [5.4 3.  4.5 1.5], Saída prevista: [0.99624766], Saída real: 1\n",
      "Instância de teste: [5.2 3.4 1.4 0.2], Saída prevista: [0.00583719], Saída real: 0\n",
      "Instância de teste: [6.1 2.8 4.  1.3], Saída prevista: [0.99636973], Saída real: 1\n",
      "Instância de teste: [5.5 2.4 3.7 1. ], Saída prevista: [0.99592454], Saída real: 1\n",
      "Instância de teste: [5.6 3.  4.1 1.3], Saída prevista: [0.99588232], Saída real: 1\n",
      "Instância de teste: [4.5 2.3 1.3 0.3], Saída prevista: [0.00720655], Saída real: 0\n",
      "Instância de teste: [5.  3.5 1.6 0.6], Saída prevista: [0.00618365], Saída real: 0\n",
      "Instância de teste: [5.  2.3 3.3 1. ], Saída prevista: [0.99251523], Saída real: 1\n",
      "Instância de teste: [4.9 3.1 1.5 0.2], Saída prevista: [0.00602828], Saída real: 0\n",
      "Instância de teste: [4.6 3.1 1.5 0.2], Saída prevista: [0.00590545], Saída real: 0\n",
      "Instância de teste: [6.3 2.5 4.9 1.5], Saída prevista: [0.99654018], Saída real: 1\n",
      "Instância de teste: [4.8 3.  1.4 0.1], Saída prevista: [0.00595989], Saída real: 0\n",
      "Instância de teste: [5.1 3.4 1.5 0.2], Saída prevista: [0.00583206], Saída real: 0\n",
      "Instância de teste: [5.7 2.8 4.5 1.3], Saída prevista: [0.99638262], Saída real: 1\n",
      "Instância de teste: [5.  3.4 1.5 0.2], Saída prevista: [0.00579986], Saída real: 0\n",
      "Instância de teste: [5.1 3.8 1.6 0.2], Saída prevista: [0.00562684], Saída real: 0\n",
      "Instância de teste: [5.7 4.4 1.5 0.4], Saída prevista: [0.00545713], Saída real: 0\n",
      "Instância de teste: [6.1 2.9 4.7 1.4], Saída prevista: [0.99643959], Saída real: 1\n",
      "Instância de teste: [5.1 3.7 1.5 0.4], Saída prevista: [0.00572461], Saída real: 0\n",
      "Instância de teste: [6.3 3.3 4.7 1.6], Saída prevista: [0.99636789], Saída real: 1\n",
      "Instância de teste: [5.4 3.4 1.7 0.2], Saída prevista: [0.00613615], Saída real: 0\n",
      "Instância de teste: [6.2 2.9 4.3 1.3], Saída prevista: [0.99638987], Saída real: 1\n",
      "Acurácia: 100.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Carrega o dataset Iris do sklearn\n",
    "iris = load_iris()\n",
    "X = iris.data[:100]  # Usamos apenas as primeiras 100 amostras (setosa e versicolor)\n",
    "y = iris.target[:100]  # Convertido automaticamente para 0 (setosa) e 1 (versicolor)\n",
    "\n",
    "# Cria um objeto Dataset\n",
    "dataset = Dataset(X=X, Y=y)\n",
    "\n",
    "# Divide o conjunto de dados em treino e teste\n",
    "X_train, y_train, X_test, y_test = dataset.train_test_split(p=0.7)\n",
    "\n",
    "# Cria um conjunto de dados de treino para o MLP\n",
    "train_dataset = Dataset(X=X_train, Y=y_train)\n",
    "\n",
    "# Cria e treina o modelo MLP\n",
    "mlp = MLP(conjunto_dados=train_dataset, nos_ocultos=5, normalizar=True)\n",
    "mlp.construir_modelo()\n",
    "\n",
    "# Faz previsões com o modelo treinado\n",
    "correct = 0\n",
    "for i in range(len(X_test)):\n",
    "    test_instance = X_test[i]\n",
    "    prediction = mlp.prever(test_instance)\n",
    "    print(f\"Instância de teste: {test_instance}, Saída prevista: {prediction}, Saída real: {y_test[i]}\")\n",
    "    if round(prediction.item()) == y_test[i]:\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct / len(X_test)\n",
    "print(f\"Acurácia: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testes \"Unittest\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi realizado um teste utilizando o unittest para testar a implementação do MLP. Temos então o seguinte teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.177s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "import numpy as np\n",
    "\n",
    "class TestMLP(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        # Inicializa os dados de entrada (X) e saída (y) para o dataset\n",
    "        self.X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "        self.y = np.array([0, 1, 1, 0])\n",
    "        # Cria uma instância de Dataset com os dados X e y\n",
    "        self.dataset = Dataset(X=self.X, Y=self.y)\n",
    "        # Cria uma instância de MLP com o dataset criado e 2 neurônios na camada oculta\n",
    "        self.mlp = MLP(self.dataset, nos_ocultos=2)\n",
    "\n",
    "    def test_prever(self):\n",
    "        # Define os pesos iniciais da rede MLP\n",
    "        self.mlp.definir_pesos(\n",
    "            np.array([[0.5, 0.5, 0.5], [-0.5, -0.5, -0.5]]),\n",
    "            np.array([[-1, 1, 1]])\n",
    "        )\n",
    "        # Realiza previsões com a rede MLP para todas as entradas do dataset\n",
    "        previsoes = np.array([self.mlp.prever(self.X[i]) for i in range(4)])\n",
    "        # Arredonda as previsões para inteiros\n",
    "        previsoes = np.round(previsoes).astype(int)\n",
    "        # Calcula a acurácia das previsões\n",
    "        acuracia = np.sum(previsoes == self.y) / len(self.y)\n",
    "        # Testa se a acurácia é maior ou igual a 0.5\n",
    "        self.assertGreaterEqual(acuracia, 0.5)\n",
    "\n",
    "    def test_funcao_custo(self):\n",
    "        # Define os pesos iniciais da rede MLP\n",
    "        self.mlp.definir_pesos(\n",
    "            np.array([[0.5, 0.5, 0.5], [-0.5, -0.5, -0.5]]),\n",
    "            np.array([[-1, 1, 1]])\n",
    "        )\n",
    "        # Calcula o valor da função custo da rede MLP\n",
    "        custo = self.mlp.funcao_custo()\n",
    "        # Testa se o valor do custo é menor que 0.5\n",
    "        self.assertLess(custo, 0.5)\n",
    "\n",
    "    def test_construir_modelo(self):\n",
    "        # Treina o modelo da rede MLP\n",
    "        self.mlp.construir_modelo()\n",
    "        # Realiza previsões com a rede MLP treinada para todas as entradas do dataset\n",
    "        previsoes = np.array([self.mlp.prever(self.X[i]) for i in range(4)])\n",
    "        # Arredonda as previsões para inteiros\n",
    "        previsoes = np.round(previsoes).astype(int)\n",
    "        # Calcula a acurácia das previsões\n",
    "        acuracia = np.sum(previsoes == self.y) / len(self.y)\n",
    "        # Testa se a acurácia é maior ou igual a 0.5\n",
    "        self.assertGreaterEqual(acuracia, 0.5)\n",
    "\n",
    "    def test_normalizar_dados(self):\n",
    "        # Normaliza os dados de entrada da rede MLP\n",
    "        self.mlp.normalizar_dados()\n",
    "        # Testa se a média dos atributos normalizados é próxima de 0\n",
    "        self.assertTrue(np.allclose(np.mean(self.mlp.Atributos[:, 1:], axis=0), 0))\n",
    "        # Testa se o desvio padrão dos atributos normalizados é próximo de 1\n",
    "        self.assertTrue(np.allclose(np.std(self.mlp.Atributos[:, 1:], axis=0), 1))\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    # Executa todos os testes definidos na classe TestMLP\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
