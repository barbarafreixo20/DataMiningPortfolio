{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import numpy as np\n","\n","class NaiveBayes:\n","    def fit(self, X, y):\n","        n_samples, n_features = X.shape\n","        self._classes = np.unique(y)\n","        n_classes = len(self._classes)\n","\n","        # Inicializa os parâmetros\n","        self._mean = np.zeros((n_classes, n_features), dtype=np.float64)\n","        self._variance = np.zeros((n_classes, n_features), dtype=np.float64)\n","        self._priors = np.zeros(n_classes, dtype=np.float64)\n","\n","        # Calcula os parâmetros para cada classe\n","        for idx, c in enumerate(self._classes):\n","            X_c = X[y==c]\n","            self._mean[idx, :] = X_c.mean(axis=0)\n","            self._variance[idx, :] = X_c.var(axis=0)\n","            self._priors[idx] = X_c.shape[0] / float(n_samples)\n","\n","    def predict(self, X):\n","        y_pred = [self._predict(x) for x in X]\n","        return np.array(y_pred)\n","\n","    def _predict(self, x):\n","        posteriors = []\n","\n","        # Calcula a probabilidade posterior para cada classe\n","        for idx, c in enumerate(self._classes):\n","            prior = np.log(self._priors[idx])\n","            posterior = np.sum(np.log(self._pdf(idx, x)))\n","            posterior = prior + posterior\n","            posteriors.append(posterior)\n","\n","        # Retorna a classe com a maior probabilidade posterior\n","        return self._classes[np.argmax(posteriors)]\n","\n","    def _pdf(self, class_idx, x):\n","        mean = self._mean[class_idx]\n","        var = self._variance[class_idx]\n","        numerator = np.exp(-(x-mean)**2 / (2 * var))\n","        denominator = np.sqrt(2 * np.pi * var)\n","        return numerator / denominator"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Acurácia: 1.00\n"]}],"source":["import numpy as np\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","\n","# Carrega o conjunto de dados Iris\n","iris = load_iris()\n","X, y = iris.data, iris.target\n","\n","# Divide os dados em conjunto de treino e teste\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Instancia o modelo Naive Bayes e treina-o com os dados de treino\n","model = NaiveBayes()\n","model.fit(X_train, y_train)\n","\n","# Faz a previsão das classes para os dados de teste\n","y_pred = model.predict(X_test)\n","\n","# Calcula a acurácia da previsão\n","accuracy = np.mean(y_pred == y_test)\n","print(f\"Acurácia: {accuracy:.2f}\")"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Acurácia: 0.96\n"]}],"source":["import numpy as np\n","from sklearn.datasets import load_breast_cancer\n","from sklearn.model_selection import train_test_split\n","\n","# Carrega o conjunto de dados Breast Cancer Wisconsin\n","cancer = load_breast_cancer()\n","X, y = cancer.data, cancer.target\n","\n","# Divide os dados em conjunto de treino e teste\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Instancia o modelo Naive Bayes e treina-o com os dados de treino\n","model = NaiveBayes()\n","model.fit(X_train, y_train)\n","\n","# Faz a previsão das classes para os dados de teste\n","y_pred = model.predict(X_test)\n","\n","# Calcula a acurácia da previsão\n","accuracy = np.mean(y_pred == y_test)\n","print(f\"Acurácia: {accuracy:.2f}\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
