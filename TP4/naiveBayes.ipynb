{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Trabalho realizado por: Bárbara Freixo, PG49169\n","\n","Nesta notebook será implementado o Multinomial Naive Bayes Classifier, o Bernoulli Naive Bayes Classifier e o Gaussian Naive Bayes Classifier.\n","\n","O Classificador Naive Bayes Multinomial é um modelo de classificação baseado no Teorema de Bayes que supõe que as características seguem uma distribuição multinomial. É utilizado principalmente para a classificação de texto, onde as características são representadas pelo número de ocorrências de palavras.\n","\n","O Classificador Naive Bayes de Bernoulli é semelhante ao Classificador Naive Bayes Multinomial, mas pressupõe que as características seguem uma distribuição de Bernoulli, ou seja, cada característica representa a presença ou ausência de uma determinada característica. É frequentemente utilizado para classificação binária.\n","\n","O Classificador Naive Bayes Gaussiano é outro modelo de classificação baseado no Teorema de Bayes que supe que as características seguem uma distribuição normal. É principalmente utilizado para a classificação de dados numéricos, onde as características podem ser representadas por uma distribuição normal.\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import numpy as np\n","\n","class MultinomialNaiveBayesClassifier:\n","    \"\"\"\n","    A classifier that uses the multinomial naive bayes algorithm.\n","    The model assumes that the features are multinomial distributions.\n","    It is used primarily for text classification where the features are word counts.\n","    \"\"\"\n","    def __init__(self, alpha=1.0):\n","        \"\"\"\n","        Initialize the classifier with an optional smoothing factor (alpha).\n","        \"\"\"\n","        self.alpha = alpha\n","        self.classes = None\n","        self.class_probs = None\n","        self.feature_probs = None\n","\n","    def fit(self, X, y):\n","        \"\"\"\n","        Fit the classifier to the training data.\n","        X: a 2D numpy array of shape (n_samples, n_features)\n","        y: a 1D numpy array of shape (n_samples,)\n","        \"\"\"\n","        self.classes, counts = np.unique(y, return_counts=True)\n","        self.class_probs = counts / y.shape[0]\n","\n","        n_classes = len(self.classes)\n","        n_features = X.shape[1]\n","\n","        self.feature_probs = np.zeros((n_classes, n_features))\n","\n","        for i, cls in enumerate(self.classes):\n","            X_cls = X[y == cls]\n","            self.feature_probs[i, :] = (X_cls.sum(axis=0) + self.alpha) / (np.sum(X_cls) + self.alpha * n_features)\n","\n","    def predict(self, X):\n","        \"\"\"\n","        Predict the class labels for a set of samples.\n","        X: a 2D numpy array of shape (n_samples, n_features)\n","        Returns: a 1D numpy array of shape (n_samples,)\n","        \"\"\"\n","        log_probs = np.log(self.class_probs) + X @ np.log1p(np.clip(self.feature_probs.T, a_min=np.finfo(float).eps, a_max=None))\n","        return self.classes[np.argmax(log_probs, axis=1)]"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Exemplo de uso"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Multinomial Naive Bayes Accuracy: 0.8722222222222222\n"]}],"source":["# Data Splitting\n","from sklearn.datasets import load_digits\n","from sklearn.model_selection import train_test_split\n","\n","# Load Digits dataset from scikit-learn library\n","digits = load_digits()\n","X, y = digits.data, digits.target\n","\n","# Split data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","# Create an instance of MultinomialNaiveBayesClassifier with a smoothing parameter alpha=1.0\n","mnb = MultinomialNaiveBayesClassifier(alpha=1.0)\n","\n","# Fit the classifier to the training data\n","mnb.fit(X_train, y_train)\n","\n","# Predict the labels of the test data\n","y_pred = mnb.predict(X_test)\n","\n","# Calculate the accuracy of the classifier\n","accuracy = np.mean(y_test == y_pred)\n","print(\"Multinomial Naive Bayes Accuracy:\", accuracy)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Teste \"Unittest\""]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["..\n","----------------------------------------------------------------------\n","Ran 2 tests in 0.014s\n","\n","OK\n"]}],"source":["import unittest\n","import numpy as np\n","from sklearn.datasets import make_classification\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","class TestMultinomialNaiveBayesClassifier(unittest.TestCase):\n","    \"\"\"\n","    Test class for the MultinomialNaiveBayesClassifier\n","    \"\"\"\n","\n","    def setUp(self):\n","        \"\"\"\n","        Initialize the classifier\n","        \"\"\"\n","        self.clf = MultinomialNaiveBayesClassifier()\n","\n","    def test_fit(self):\n","        \"\"\"\n","        Test the fit method of the classifier\n","        \"\"\"\n","        X, y = make_classification(n_samples=100, n_features=20, n_classes=3, n_informative=3, random_state=42)\n","        self.clf.fit(X, y)\n","        # Check if the classes, class probabilities and feature probabilities are set\n","        self.assertIsNotNone(self.clf.classes)\n","        self.assertIsNotNone(self.clf.class_probs)\n","        self.assertIsNotNone(self.clf.feature_probs)\n","\n","    def test_predict(self):\n","        \"\"\"\n","        Test the predict method of the classifier\n","        \"\"\"\n","        X, y = make_classification(n_samples=100, n_features=20, n_classes=3, n_informative=3, random_state=42)\n","        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n","        self.clf.fit(X_train, y_train)\n","        y_pred = self.clf.predict(X_test)\n","        # Check if the predictions are not None and the length of the predictions is equal to the length of the test data\n","        self.assertIsNotNone(y_pred)\n","        self.assertEqual(len(y_pred), len(y_test))\n","\n","if __name__ == \"__main__\":\n","    unittest.main(argv=['first-arg-is-ignored'], exit=False)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["import numpy as np\n","\n","class BernoulliNaiveBayesClassifier:\n","    \"\"\"\n","    A Bernoulli Naive Bayes Classifier model. This model is based on Bayes' theorem and assumes that the features are Bernoulli distributions, \n","    meaning that each feature represents the presence or absence of a characteristic. It is commonly used for binary classification.\n","    \"\"\"\n","\n","    def __init__(self, alpha=1.0):\n","        \"\"\"\n","        Initialize the classifier with a smoothing parameter alpha.\n","        \n","        Parameters:\n","        - alpha (float): Smoothing parameter to handle cases where features are not present in the training data.\n","        \n","        Returns:\n","        None\n","        \"\"\"\n","        self.alpha = alpha\n","        self.classes = None\n","        self.class_probs = None\n","        self.feature_probs = None\n","\n","    def fit(self, X, y):\n","        \"\"\"\n","        Fit the classifier to the training data.\n","        \n","        Parameters:\n","        - X (numpy array): Features of the training data.\n","        - y (numpy array): Labels of the training data.\n","        \n","        Returns:\n","        None\n","        \"\"\"\n","        self.classes, counts = np.unique(y, return_counts=True)\n","        if np.all(counts > 0):\n","            self.class_probs = counts / y.shape[0]\n","        else:\n","            raise ValueError(\"Classes with zero examples not supported\")\n","\n","        n_classes = len(self.classes)\n","        n_features = X.shape[1]\n","\n","        self.feature_probs = np.zeros((n_classes, n_features))\n","\n","        for i, cls in enumerate(self.classes):\n","            X_cls = X[y == cls]\n","            if X_cls.shape[0] > 0:\n","                self.feature_probs[i, :] = (X_cls.sum(axis=0) + self.alpha) / (X_cls.shape[0] + 2 * self.alpha)\n","            else:\n","                raise ValueError(\"Classes with zero examples not supported\")\n","\n","    def predict(self, X):\n","        \"\"\"\n","        Predict the class labels for the given feature data.\n","        \n","        Parameters:\n","        - X (numpy array): Features of the data to be classified.\n","        \n","        Returns:\n","        - numpy array: Predicted class labels.\n","        \"\"\"\n","        log_feature_probs = np.log(self.feature_probs)\n","        log_feature_probs_neg = np.log(1 - self.feature_probs)\n","        log_probs = np.zeros((X.shape[0], len(self.classes)))\n","\n","        for i, x in enumerate(X):\n","            log_probs[i] = np.log(self.class_probs) + np.sum(x * log_feature_probs - x * log_feature_probs_neg + log_feature_probs_neg, axis=1)\n","\n","        return self.classes[np.argmax(log_probs, axis=1)]"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Exemplo de uso"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Bernoulli Naive Bayes Accuracy: 0.8592592592592593\n"]}],"source":["# This code trains and tests a Bernoulli Naive Bayes classifier using the binarized version of the digits dataset from scikit-learn.\n","# The classifier is initialized with an alpha value of 1.0, and is trained using the fit method on the training data. \n","# The accuracy of the classifier is then computed by comparing its predictions on the test data to the actual target values, and printing the resulting accuracy.\n","\n","from sklearn.datasets import load_digits\n","from sklearn.preprocessing import binarize\n","from sklearn.model_selection import train_test_split\n","\n","# Load the digits dataset and extract features and target variables\n","digits = load_digits()\n","X, y = digits.data, digits.target\n","\n","# Binarize the data\n","X = binarize(X)\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","# Initialize the Bernoulli Naive Bayes classifier with alpha = 1.0\n","bnb = BernoulliNaiveBayesClassifier(alpha=1.0)\n","\n","# Fit the classifier on the training data\n","bnb.fit(X_train, y_train)\n","\n","# Predict on the test data\n","y_pred = bnb.predict(X_test)\n","\n","# Compute the accuracy of the classifier by comparing its predictions to the actual target values\n","accuracy = np.mean(y_test == y_pred)\n","\n","# Print the accuracy\n","print(\"Bernoulli Naive Bayes Accuracy:\", accuracy)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Teste \"Unittest\""]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["......\n","----------------------------------------------------------------------\n","Ran 6 tests in 0.016s\n","\n","OK\n"]}],"source":["import numpy as np\n","import unittest\n","from sklearn.model_selection import train_test_split\n","from sklearn.datasets import make_classification\n","from sklearn.metrics import accuracy_score\n","\n","class TestBernoulliNaiveBayesClassifier(unittest.TestCase):\n","    \"\"\"\n","    A class for testing the BernoulliNaiveBayesClassifier.\n","    \"\"\"\n","    def setUp(self):\n","        \"\"\"\n","        Initialize the classifier object.\n","        \"\"\"\n","        self.classifier = BernoulliNaiveBayesClassifier()\n","\n","    def test_init(self):\n","        \"\"\"\n","        Test the initialization of the classifier object.\n","        \"\"\"\n","        self.assertEqual(self.classifier.alpha, 1.0)\n","        self.assertIsNone(self.classifier.classes)\n","        self.assertIsNone(self.classifier.class_probs)\n","        self.assertIsNone(self.classifier.feature_probs)\n","\n","    def test_fit(self):\n","        \"\"\"\n","        Test the fit method of the classifier.\n","        \"\"\"\n","        X, y = make_classification(n_samples=100, n_features=10, random_state=42)\n","        X = (X > 0).astype(int)\n","        self.classifier.fit(X, y)\n","        self.assertIsNotNone(self.classifier.classes)\n","        self.assertIsNotNone(self.classifier.class_probs)\n","        self.assertIsNotNone(self.classifier.feature_probs)\n","\n","    def test_predict(self):\n","        \"\"\"\n","        Test the predict method of the classifier.\n","        \"\"\"\n","        X, y = make_classification(n_samples=100, n_features=10, random_state=42)\n","        X = (X > 0).astype(int)\n","        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","        self.classifier.fit(X_train, y_train)\n","        y_pred = self.classifier.predict(X_test)\n","        self.assertIsNotNone(y_pred)\n","        self.assertEqual(len(y_pred), len(y_test))\n","\n","    def test_accuracy(self):\n","        \"\"\"\n","        Test the accuracy of the classifier.\n","        \"\"\"\n","        X, y = make_classification(n_samples=100, n_features=10, random_state=42)\n","        X = (X > 0).astype(int)\n","        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","        self.classifier.fit(X_train, y_train)\n","        y_pred = self.classifier.predict(X_test)\n","        accuracy = accuracy_score(y_test, y_pred)\n","        self.assertGreater(accuracy, 0.5)\n","\n","if __name__ == \"__main__\":\n","    unittest.main(argv=['first-arg-is-ignored'], exit=False)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["import numpy as np\n","\n","class GaussianNaiveBayesClassifier:\n","    \"\"\"\n","    Gaussian Naive Bayes Classifier\n","\n","    This classifier implements the Gaussian Naive Bayes algorithm for classification.\n","    The algorithm assumes that the features are normally distributed and uses the mean\n","    and variance of each feature for each class to calculate the class probabilities.\n","    \"\"\"\n","\n","    def __init__(self):\n","        \"\"\"\n","        Initialize the classifier.\n","        \"\"\"\n","        self.classes = None\n","        self.class_prior = None\n","        self.mean = None\n","        self.var = None\n","        \n","    def fit(self, X, y):\n","        \"\"\"\n","        Fit the classifier to the training data.\n","\n","        Parameters:\n","            X (numpy.ndarray): The training data.\n","            y (numpy.ndarray): The target labels.\n","        \"\"\"\n","        self.classes, counts = np.unique(y, return_counts=True)\n","        self.class_prior = counts / y.shape[0]\n","        \n","        n_classes = len(self.classes)\n","        n_features = X.shape[1]\n","        \n","        self.mean = np.zeros((n_classes, n_features))\n","        self.var = np.zeros((n_classes, n_features))\n","        \n","        for i, cls in enumerate(self.classes):\n","            X_cls = X[y == cls]\n","            self.mean[i, :] = X_cls.mean(axis=0)\n","            self.var[i, :] = X_cls.var(axis=0)\n","    \n","    def predict(self, X):\n","        \"\"\"\n","        Predict the class labels for the given data.\n","\n","        Parameters:\n","            X (numpy.ndarray): The data to predict.\n","\n","        Returns:\n","            numpy.ndarray: The predicted class labels.\n","        \"\"\"\n","        log_likelihood = -0.5 * np.sum(np.log(2.0 * np.pi * self.var), axis=1) \\\n","                         -0.5 * np.sum((X[:, np.newaxis] - self.mean) ** 2 / self.var, axis=2)\n","        log_probs = np.log(self.class_prior) + log_likelihood\n","        return self.classes[np.argmax(log_probs, axis=1)]"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Exemplo de uso"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Gaussian Naive Bayes Accuracy: 0.9666666666666667\n"]}],"source":["from sklearn.model_selection import train_test_split\n","\n","# Set seed for reproducibility\n","np.random.seed(42)\n","\n","# Generate data\n","n_samples = 300\n","X1 = np.random.normal(2, 1, (n_samples // 2, 2))\n","X2 = np.random.normal(5, 1, (n_samples // 2, 2))\n","X = np.vstack((X1, X2))\n","y = np.hstack((np.zeros(n_samples // 2), np.ones(n_samples // 2)))\n","\n","# Split data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","# Fit Gaussian Naive Bayes classifier and predict test data\n","gnb = GaussianNaiveBayesClassifier()\n","gnb.fit(X_train, y_train)\n","y_pred = gnb.predict(X_test)\n","\n","# Calculate accuracy\n","accuracy = np.mean(y_test == y_pred)\n","print(\"Gaussian Naive Bayes Accuracy:\", accuracy)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Teste \"Unittest\""]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["........\n","----------------------------------------------------------------------\n","Ran 8 tests in 0.022s\n","\n","OK\n"]}],"source":["import unittest\n","import numpy as np\n","\n","class TestGaussianNaiveBayesClassifier(unittest.TestCase):\n","\n","    def setUp(self):\n","        self.X = np.array([[1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7]])\n","        self.y = np.array([0, 0, 0, 1, 1, 1])\n","\n","        self.clf = GaussianNaiveBayesClassifier()\n","        self.clf.fit(self.X, self.y)\n","\n","    # Test the fit method of the GaussianNaiveBayesClassifier\n","    def test_fit(self):\n","        np.testing.assert_array_equal(self.clf.classes, np.array([0, 1]))\n","        np.testing.assert_almost_equal(self.clf.class_prior, np.array([0.5, 0.5]), decimal=6)\n","\n","        np.testing.assert_almost_equal(self.clf.mean, np.array([[2., 3.], [5., 6.]]), decimal=6)\n","        np.testing.assert_almost_equal(self.clf.var, np.array([[0.66666667, 0.66666667], [0.66666667, 0.66666667]]), decimal=6)\n","\n","    # Test the predict method of the GaussianNaiveBayesClassifier\n","    def test_predict(self):\n","        X_test = np.array([[1.5, 2.5], [4.5, 5.5]])\n","        y_pred = self.clf.predict(X_test)\n","        np.testing.assert_array_equal(y_pred, np.array([0, 1]))\n","\n","if __name__ == \"__main__\":\n","    unittest.main(argv=['first-arg-is-ignored'], exit=False)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
