{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trabalho realizado por: Bárbara Freixo, PG49169\n",
    "\n",
    "Este código implementa o algoritmo Apriori para mineração de regras de associação. O objetivo é encontrar padrões frequentes num conjunto de transações, sendo que cada transação é uma lista de itens. O processo começa por gerar conjuntos de itens candidatos a partir dos itens únicos nas transações e, em seguida, conta-se a ocorrência de cada conjunto de itens nas transações. Conjuntos com ocorrência abaixo do suporte mínimo são descartados. Com base nos conjuntos frequentes, são gerados novos conjuntos candidatos, repetindo-se o processo até não haver mais conjuntos candidatos. Finalmente, as regras de associação são geradas com base na confiança mínima.\n",
    "\n",
    "A classe TransactionDataset representa um conjunto de transações, sendo que cada transação é uma lista de itens. O método get_unique_items é usado para obter uma lista dos itens únicos presentes em todas as transações. O método get_frequent_items é usado para obter itens frequentes em ordem inversa de frequência.\n",
    "\n",
    "A classe Apriori implementa o algoritmo Apriori para mineração de regras de associação. O método count_itemsets é usado para contar a frequência de cada conjunto de itens candidato nas transações. O método prune_itemsets descarta os conjuntos de itens que têm suporte abaixo do suporte mínimo. O método generate_candidate_itemsets gera novos conjuntos de itens candidatos a partir dos conjuntos frequentes. O método apriori_algorithm é o método principal que executa o algoritmo Apriori.\n",
    "\n",
    "A função association_rules gera regras de associação a partir dos conjuntos frequentes, baseadas na confiança mínima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict, OrderedDict\n",
    "from itertools import combinations\n",
    "import unittest\n",
    "\n",
    "# Classe para representar um conjunto de transações (cada transação é uma lista de itens)\n",
    "class TransactionDataset:\n",
    "    def __init__(self, transactions):\n",
    "        self.transactions = transactions  # Lista de transações\n",
    "        self.items = self.get_unique_items()  # Lista de itens únicos\n",
    "        self.frequent_items = self.get_frequent_items()  # Frequent items in reverse frequency order\n",
    "\n",
    "    # Método para obter itens únicos em todas as transações\n",
    "    def get_unique_items(self):\n",
    "        unique_items = set()\n",
    "        for transaction in self.transactions:\n",
    "            for item in transaction:\n",
    "                unique_items.add(item)\n",
    "        return sorted(list(unique_items))\n",
    "\n",
    "    # Método para obter itens frequentes em ordem inversa de frequência\n",
    "    def get_frequent_items(self):\n",
    "        item_counts = defaultdict(int)\n",
    "        for transaction in self.transactions:\n",
    "            for item in transaction:\n",
    "                item_counts[item] += 1\n",
    "        return OrderedDict(sorted(item_counts.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "# Classe para implementar o algoritmo Apriori\n",
    "class Apriori:\n",
    "    def __init__(self, transaction_dataset, min_support):\n",
    "        self.transaction_dataset = transaction_dataset  # Objeto TransactionDataset\n",
    "        self.min_support = min_support  # Suporte mínimo\n",
    "        self.itemsets = self.apriori_algorithm()  # Conjuntos de itens frequentes\n",
    "\n",
    "    # Método para contar a ocorrência de cada conjunto de itens candidato nas transações\n",
    "    def count_itemsets(self, candidate_itemsets):\n",
    "        counts = defaultdict(int)\n",
    "        for transaction in self.transaction_dataset.transactions:\n",
    "            for itemset in candidate_itemsets:\n",
    "                if set(itemset).issubset(transaction):\n",
    "                    counts[itemset] += 1\n",
    "        return counts\n",
    "\n",
    "    # Método para podar conjuntos de itens com suporte abaixo do mínimo\n",
    "    def prune_itemsets(self, counts):\n",
    "        pruned_itemsets = []\n",
    "        for itemset, count in counts.items():\n",
    "            if count / len(self.transaction_dataset.transactions) >= self.min_support:\n",
    "                pruned_itemsets.append(itemset)\n",
    "        return pruned_itemsets\n",
    "\n",
    "    # Método para gerar novos conjuntos de itens candidatos a partir dos conjuntos frequentes\n",
    "    def generate_candidate_itemsets(self, frequent_itemsets):\n",
    "        candidates = set()\n",
    "        for itemset1 in frequent_itemsets:\n",
    "            for itemset2 in frequent_itemsets:\n",
    "                union = tuple(sorted(set(itemset1).union(itemset2)))\n",
    "                if len(union) == len(itemset1) + 1:\n",
    "                    candidates.add(union)\n",
    "        return candidates\n",
    "\n",
    "    # Método principal para executar o algoritmo Apriori\n",
    "    def apriori_algorithm(self):\n",
    "        itemsets = []\n",
    "        candidate_itemsets = [tuple([item]) for item in self.transaction_dataset.items]\n",
    "        while candidate_itemsets:\n",
    "            counts = self.count_itemsets(candidate_itemsets)\n",
    "            frequent_itemsets = self.prune_itemsets(counts)\n",
    "            itemsets.extend(frequent_itemsets)\n",
    "            candidate_itemsets = self.generate_candidate_itemsets(frequent_itemsets)\n",
    "        return itemsets\n",
    "\n",
    "# Função para gerar regras de associação a partir dos conjuntos frequentes\n",
    "def association_rules(apriori, min_confidence):\n",
    "    rules = []\n",
    "    for itemset in apriori.itemsets:\n",
    "        if len(itemset) < 2:\n",
    "            continue\n",
    "        for i in range(1, len(itemset)):\n",
    "            for c in combinations(itemset, i):\n",
    "                antecedent = tuple(sorted(c))\n",
    "                consequent = tuple(sorted(set(itemset).difference(antecedent)))\n",
    "                antecedent_support = apriori.count_itemsets([antecedent])[antecedent] / len(apriori.transaction_dataset.transactions)\n",
    "                itemset_support = apriori.count_itemsets([itemset])[itemset] / len(apriori.transaction_dataset.transactions)\n",
    "                confidence = itemset_support / antecedent_support\n",
    "                if confidence >= min_confidence:\n",
    "                    rules.append((antecedent, consequent, confidence))\n",
    "    return rules"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testes e exemplos para o algoritmo implementado"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo de uso do código"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos supor que temos uma lista de transações que representam compras numa loja, onde cada transação é uma lista de itens comprados por um cliente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = [    ['leite', 'pão', 'manteiga'],\n",
    "    ['leite', 'pão'],\n",
    "    ['leite', 'pão', 'ovos'],\n",
    "    ['leite', 'pão', 'manteiga', 'ovos'],\n",
    "    ['leite', 'ovos'],\n",
    "    ['pão', 'manteiga', 'ovos'],\n",
    "    ['pão', 'manteiga']\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para executar o algoritmo Apriori, primeiro precisamos de criar um objeto TransactionDataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique items: ['leite', 'manteiga', 'ovos', 'pão']\n",
      "Frequent items in reverse frequency order: OrderedDict([('pão', 6), ('leite', 5), ('manteiga', 4), ('ovos', 4)])\n"
     ]
    }
   ],
   "source": [
    "transaction_dataset = TransactionDataset(transactions)\n",
    "print(\"Unique items:\", transaction_dataset.items)\n",
    "print(\"Frequent items in reverse frequency order:\", transaction_dataset.frequent_items)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, podemos criar um objeto Apriori com um suporte mínimo de 0,3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent itemsets: [('leite',), ('manteiga',), ('pão',), ('ovos',), ('manteiga', 'pão'), ('leite', 'pão'), ('leite', 'ovos'), ('ovos', 'pão')]\n"
     ]
    }
   ],
   "source": [
    "apriori = Apriori(transaction_dataset, min_support=0.3)\n",
    "print(\"Frequent itemsets:\", apriori.itemsets)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, podemos gerar as regras de associação com uma confiança mínima de 0,5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antecedente:  ('manteiga',)\n",
      "Consequente:  ('pão',)\n",
      "Confiança:  1.0\n",
      "\n",
      "\n",
      "Antecedente:  ('pão',)\n",
      "Consequente:  ('manteiga',)\n",
      "Confiança:  0.67\n",
      "\n",
      "\n",
      "Antecedente:  ('leite',)\n",
      "Consequente:  ('pão',)\n",
      "Confiança:  0.8\n",
      "\n",
      "\n",
      "Antecedente:  ('pão',)\n",
      "Consequente:  ('leite',)\n",
      "Confiança:  0.67\n",
      "\n",
      "\n",
      "Antecedente:  ('leite',)\n",
      "Consequente:  ('ovos',)\n",
      "Confiança:  0.6\n",
      "\n",
      "\n",
      "Antecedente:  ('ovos',)\n",
      "Consequente:  ('leite',)\n",
      "Confiança:  0.75\n",
      "\n",
      "\n",
      "Antecedente:  ('ovos',)\n",
      "Consequente:  ('pão',)\n",
      "Confiança:  0.75\n",
      "\n",
      "\n",
      "Antecedente:  ('pão',)\n",
      "Consequente:  ('ovos',)\n",
      "Confiança:  0.5\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rules = association_rules(apriori, 0.5)\n",
    "for antecedent, consequent, confidence in rules:\n",
    "    print(\"Antecedente: \", antecedent)\n",
    "    print(\"Consequente: \", consequent)\n",
    "    print(\"Confiança: \", round(confidence,2))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As regras de associação geradas representam padrões frequentes nas compras dos clientes, como por exemplo: se um cliente compra leite, ele também compra pão com uma confiança de 0.8."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testes \"Unittest\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foram realizados dois testes utilizando o unittest para testar a implementação do algoritmo Apriori. Temos então o primeiro teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "class TestTransactionDataset(unittest.TestCase):\n",
    "    def test_get_unique_items(self):\n",
    "        \"\"\"\n",
    "        Testa a função get_unique_items, que deve retornar uma lista de itens únicos encontrados nas transações.\n",
    "        \"\"\"\n",
    "        transactions = [['a', 'b'], ['b', 'c'], ['a', 'c']]\n",
    "        dataset = TransactionDataset(transactions)\n",
    "        self.assertEqual(dataset.get_unique_items(), ['a', 'b', 'c'])\n",
    "    def test_get_frequent_items(self):\n",
    "        \"\"\"\n",
    "        Testa a função get_frequent_items, que deve retornar itens frequentes na ordem inversa de frequência.\n",
    "        \"\"\"\n",
    "        transactions = [['a', 'b'], ['b', 'c'], ['a', 'c']]\n",
    "        dataset = TransactionDataset(transactions)\n",
    "        frequent_items = dataset.get_frequent_items()\n",
    "        self.assertEqual(frequent_items, OrderedDict([('a', 2), ('b', 2), ('c', 2)]))\n",
    "\n",
    "class TestApriori(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        transactions = [['a', 'b'], ['b', 'c'], ['a', 'c']]\n",
    "        dataset = TransactionDataset(transactions)\n",
    "        self.apriori = Apriori(dataset, 0.5)\n",
    "\n",
    "    def test_count_itemsets(self):\n",
    "        \"\"\"\n",
    "        Testa a função count_itemsets, que deve contar corretamente a ocorrência de cada itemset candidato nas transações.\n",
    "        \"\"\"\n",
    "        candidates = [('a',), ('b',)]\n",
    "        counts = self.apriori.count_itemsets(candidates)\n",
    "        self.assertEqual(counts, {('a',): 2, ('b',): 2})\n",
    "\n",
    "    def test_prune_itemsets(self):\n",
    "        \"\"\"\n",
    "        Testa a função prune_itemsets, que deve remover itemsets infrequentes com base no suporte mínimo.\n",
    "        \"\"\"\n",
    "        counts = {('a',): 2, ('b',): 2, ('c',): 1}\n",
    "        pruned_itemsets = self.apriori.prune_itemsets(counts)\n",
    "        self.assertEqual(pruned_itemsets, [('a',), ('b',)])\n",
    "\n",
    "    def test_generate_candidate_itemsets(self):\n",
    "        \"\"\"\n",
    "        Testa a função generate_candidate_itemsets, que deve gerar itemsets candidatos a partir de itemsets frequentes.\n",
    "        \"\"\"\n",
    "        frequent_itemsets = [('a',), ('b',)]\n",
    "        candidates = self.apriori.generate_candidate_itemsets(frequent_itemsets)\n",
    "        self.assertEqual(candidates, {('a', 'b')})\n",
    "\n",
    "    def test_apriori_algorithm(self):\n",
    "        \"\"\"\n",
    "        Testa a função apriori_algorithm, que deve retornar todos os itemsets frequentes.\n",
    "        \"\"\"\n",
    "        itemsets = self.apriori.apriori_algorithm()\n",
    "        self.assertEqual(itemsets, [('a',), ('b',), ('c',)])\n",
    "\n",
    "class TestAssociationRules(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        transactions = [['a', 'b'], ['b', 'c'], ['a', 'c']]\n",
    "        dataset = TransactionDataset(transactions)\n",
    "        self.apriori = Apriori(dataset, 0.5)\n",
    "\n",
    "    def test_association_rules(self):\n",
    "        \"\"\"\n",
    "        Testa a função association_rules, que deve gerar regras de associação com base nos itemsets frequentes e confiança mínima.\n",
    "        \"\"\"\n",
    "        rules = association_rules(self.apriori, 0.6)\n",
    "        self.assertEqual(rules, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_get_frequent_items (__main__.TestTransactionDataset.test_get_frequent_items)\n",
      "Testa a função get_frequent_items, que deve retornar itens frequentes na ordem inversa de frequência. ... ok\n",
      "test_get_unique_items (__main__.TestTransactionDataset.test_get_unique_items)\n",
      "Testa a função get_unique_items, que deve retornar uma lista de itens únicos encontrados nas transações. ... ok\n",
      "test_apriori_algorithm (__main__.TestApriori.test_apriori_algorithm)\n",
      "Testa a função apriori_algorithm, que deve retornar todos os itemsets frequentes. ... ok\n",
      "test_count_itemsets (__main__.TestApriori.test_count_itemsets)\n",
      "Testa a função count_itemsets, que deve contar corretamente a ocorrência de cada itemset candidato nas transações. ... ok\n",
      "test_generate_candidate_itemsets (__main__.TestApriori.test_generate_candidate_itemsets)\n",
      "Testa a função generate_candidate_itemsets, que deve gerar itemsets candidatos a partir de itemsets frequentes. ... ok\n",
      "test_prune_itemsets (__main__.TestApriori.test_prune_itemsets)\n",
      "Testa a função prune_itemsets, que deve remover itemsets infrequentes com base no suporte mínimo. ... ok\n",
      "test_association_rules (__main__.TestAssociationRules.test_association_rules)\n",
      "Testa a função association_rules, que deve gerar regras de associação com base nos itemsets frequentes e confiança mínima. ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 7 tests in 0.018s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "def run_tests():\n",
    "    \"\"\"\n",
    "    Executa todos os testes das classes de teste TestTransactionDataset, TestApriori e TestAssociationRules.\n",
    "    Esta função cria uma suíte de teste para cada classe de teste, adiciona-as a uma lista e, em seguida, cria\n",
    "    uma suíte maior que combina todas as suítes. Por fim, um corredor de teste (TextTestRunner) é usado para\n",
    "    executar a suíte maior com uma verbosidade de 2 (resultados detalhados).\n",
    "    \"\"\"\n",
    "    # Lista das classes de teste\n",
    "    test_classes = [TestTransactionDataset, TestApriori, TestAssociationRules]\n",
    "\n",
    "    # Carregador de teste do unittest\n",
    "    loader = unittest.TestLoader()\n",
    "\n",
    "    # Lista para armazenar as suítes de teste de cada classe de teste\n",
    "    suites_list = []\n",
    "    for test_class in test_classes:\n",
    "        suite = loader.loadTestsFromTestCase(test_class)\n",
    "        suites_list.append(suite)\n",
    "\n",
    "    # Cria uma suíte de teste maior combinando todas as suítes na lista\n",
    "    big_suite = unittest.TestSuite(suites_list)\n",
    "\n",
    "    # Executa a suíte de teste maior usando um corredor de teste (TextTestRunner)\n",
    "    runner = unittest.TextTestRunner(verbosity=2)\n",
    "    runner.run(big_suite)\n",
    "\n",
    "# Executa a função run_tests para iniciar os testes\n",
    "run_tests()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos agora o segundo teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "class TestAprioriRandom(unittest.TestCase):\n",
    "    @staticmethod\n",
    "    def generate_random_transactions(num_transactions, num_items, item_pool_size):\n",
    "        \"\"\"\n",
    "        Gera uma lista de transações aleatórias, onde cada transação contém um conjunto de itens selecionados\n",
    "        aleatoriamente a partir de um conjunto de itens gerados.\n",
    "        \n",
    "        :param num_transactions: número de transações a serem geradas\n",
    "        :param num_items: número de itens em cada transação\n",
    "        :param item_pool_size: número de itens únicos disponíveis no conjunto de itens\n",
    "        :return: lista de transações\n",
    "        \"\"\"\n",
    "        item_pool = [''.join(random.choices(string.ascii_lowercase, k=3)) for _ in range(item_pool_size)]\n",
    "        transactions = []\n",
    "        for _ in range(num_transactions):\n",
    "            items = random.sample(item_pool, num_items)\n",
    "            transactions.append(items)\n",
    "        return transactions\n",
    "\n",
    "    def test_random_transactions(self):\n",
    "        \"\"\"\n",
    "        Testa o algoritmo Apriori num conjunto de transações gerados aleatoriamente. Este teste verifica se\n",
    "        todos os itemsets frequentes encontrados têm suporte maior ou igual ao suporte mínimo e se todas as regras\n",
    "        de associação geradas têm confiança maior ou igual à confiança mínima.\n",
    "        \"\"\"\n",
    "        random.seed(42)\n",
    "        transactions = self.generate_random_transactions(num_transactions=50, num_items=5, item_pool_size=20)\n",
    "        dataset = TransactionDataset(transactions)\n",
    "        apriori = Apriori(dataset, 0.2)\n",
    "        itemsets = apriori.apriori_algorithm()\n",
    "\n",
    "        for itemset in itemsets:\n",
    "            support = apriori.count_itemsets([itemset])[itemset] / len(apriori.transaction_dataset.transactions)\n",
    "            self.assertGreaterEqual(support, 0.2)\n",
    "\n",
    "        rules = association_rules(apriori, 0.5)\n",
    "        for antecedent, consequent, confidence in rules:\n",
    "            self.assertGreaterEqual(confidence, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_get_frequent_items (__main__.TestTransactionDataset.test_get_frequent_items)\n",
      "Testa a função get_frequent_items, que deve retornar itens frequentes na ordem inversa de frequência. ... ok\n",
      "test_get_unique_items (__main__.TestTransactionDataset.test_get_unique_items)\n",
      "Testa a função get_unique_items, que deve retornar uma lista de itens únicos encontrados nas transações. ... ok\n",
      "test_apriori_algorithm (__main__.TestApriori.test_apriori_algorithm)\n",
      "Testa a função apriori_algorithm, que deve retornar todos os itemsets frequentes. ... ok\n",
      "test_count_itemsets (__main__.TestApriori.test_count_itemsets)\n",
      "Testa a função count_itemsets, que deve contar corretamente a ocorrência de cada itemset candidato nas transações. ... ok\n",
      "test_generate_candidate_itemsets (__main__.TestApriori.test_generate_candidate_itemsets)\n",
      "Testa a função generate_candidate_itemsets, que deve gerar itemsets candidatos a partir de itemsets frequentes. ... ok\n",
      "test_prune_itemsets (__main__.TestApriori.test_prune_itemsets)\n",
      "Testa a função prune_itemsets, que deve remover itemsets infrequentes com base no suporte mínimo. ... ok\n",
      "test_association_rules (__main__.TestAssociationRules.test_association_rules)\n",
      "Testa a função association_rules, que deve gerar regras de associação com base nos itemsets frequentes e confiança mínima. ... ok\n",
      "test_random_transactions (__main__.TestAprioriRandom.test_random_transactions)\n",
      "Testa o algoritmo Apriori num conjunto de transações gerados aleatoriamente. Este teste verifica se ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 8 tests in 0.047s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "def run_tests2():\n",
    "    \"\"\"\n",
    "    Executa todos os testes das classes de teste TestTransactionDataset, TestApriori, TestAssociationRules\n",
    "    e TestAprioriRandom. Esta função cria uma suíte de teste para cada classe de teste, adiciona-as a uma lista\n",
    "    e, em seguida, cria uma suíte maior que combina todas as suítes. Por fim, um corredor de teste\n",
    "    (TextTestRunner) é usado para executar a suíte maior com uma verbosidade de 2 (resultados detalhados).\n",
    "    \"\"\"\n",
    "    # Lista das classes de teste\n",
    "    test_classes = [\n",
    "        TestTransactionDataset,\n",
    "        TestApriori,\n",
    "        TestAssociationRules,\n",
    "        TestAprioriRandom,\n",
    "    ]\n",
    "\n",
    "    # Carregador de teste do unittest\n",
    "    loader = unittest.TestLoader()\n",
    "\n",
    "    # Lista para armazenar as suítes de teste de cada classe de teste\n",
    "    suites_list = []\n",
    "    for test_class in test_classes:\n",
    "        suite = loader.loadTestsFromTestCase(test_class)\n",
    "        suites_list.append(suite)\n",
    "\n",
    "    # Cria uma suíte de teste maior combinando todas as suítes na lista\n",
    "    big_suite = unittest.TestSuite(suites_list)\n",
    "\n",
    "    # Executa a suíte de teste maior usando um corredor de teste (TextTestRunner)\n",
    "    runner = unittest.TextTestRunner(verbosity=2)\n",
    "    runner.run(big_suite)\n",
    "\n",
    "# Executa a função run_tests2 para iniciar os testes\n",
    "run_tests2()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
